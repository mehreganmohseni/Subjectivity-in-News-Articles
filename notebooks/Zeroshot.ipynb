{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvvOFasLEZH4"
   },
   "source": [
    "#Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_wAaP_1M251",
    "outputId": "9f5f6cec-8480-49e5-b90f-61ce048b4889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2982ZQfM96x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAcRz7ikM-bk"
   },
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/data'\n",
    "test_gr_path = f'{base_dir}/greek/test_gr_labeled.tsv'\n",
    "test_gr_unlabeled_path = f'{base_dir}/greek/test_gr_unlabeled.tsv'\n",
    "test_pol_path = f'{base_dir}/polish/test_pol_labeled.tsv'\n",
    "test_pol_unlabeled_path = f'{base_dir}/polish/test_pol_unlabeled.tsv'\n",
    "test_ro_path = f'{base_dir}/romanian/test_ro_labeled.tsv'\n",
    "test_ro_unlabeled_path = f'{base_dir}/romanian/test_ro_unlabeled.tsv'\n",
    "test_ukr_path = f'{base_dir}/ukrainian/test_ukr_labeled.tsv'\n",
    "test_ukr_unlabeled_path = f'{base_dir}/ukrainian/test_ukr_unlabeled.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DVxca6ON2WY"
   },
   "outputs": [],
   "source": [
    "test_gr_df = pd.read_csv(test_gr_path, sep='\\t')\n",
    "test_gr_unlabeled_df = pd.read_csv(test_gr_unlabeled_path, sep='\\t')\n",
    "test_pol_df = pd.read_csv(test_pol_path, sep='\\t')\n",
    "test_pol_unlabeled_df = pd.read_csv(test_pol_unlabeled_path, sep='\\t')\n",
    "test_ro_df = pd.read_csv(test_ro_path, sep='\\t')\n",
    "test_ro_unlabeled_df = pd.read_csv(test_ro_unlabeled_path, sep='\\t')\n",
    "test_ukr_df = pd.read_csv(test_ukr_path, sep='\\t')\n",
    "test_ukr_unlabeled_df = pd.read_csv(test_ukr_unlabeled_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j102q5wwPCyZ",
    "outputId": "71b1d943-4e2b-4729-b106-3d48e229aaf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped classes: {0: 'OBJ', 1: 'SUBJ'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "test_gr_df['label_id'] = le.fit_transform(test_gr_df['label'])\n",
    "test_pol_df['label_id'] = le.fit_transform(test_pol_df['label'])\n",
    "test_ro_df['label_id'] = le.fit_transform(test_ro_df['label'])\n",
    "test_ukr_df['label_id'] = le.fit_transform(test_ukr_df['label'])\n",
    "\n",
    "\n",
    "for df in (test_gr_df, test_pol_df, test_ukr_df, test_ro_df):\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "for df in (test_gr_df, test_pol_df, test_ukr_df, test_ro_df):\n",
    "    df.rename(columns={'label_id':'labels'}, inplace=True)\n",
    "\n",
    "print(\"Mapped classes:\", dict(enumerate(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHfl8htLPwv-"
   },
   "outputs": [],
   "source": [
    "test_gr_ds = Dataset.from_pandas(test_gr_df[['sentence','labels']])\n",
    "test_pol_ds = Dataset.from_pandas(test_pol_df[['sentence','labels']])\n",
    "test_ro_ds = Dataset.from_pandas(test_ro_df[['sentence','labels']])\n",
    "test_ukr_ds = Dataset.from_pandas(test_ukr_df[['sentence','labels']])\n",
    "test_gr_unlabeled_ds = Dataset.from_pandas(test_gr_unlabeled_df[['sentence']])\n",
    "test_pol_unlabeled_ds = Dataset.from_pandas(test_pol_unlabeled_df[['sentence']])\n",
    "test_ro_unlabeled_ds = Dataset.from_pandas(test_ro_unlabeled_df[['sentence']])\n",
    "test_ukr_unlabeled_ds = Dataset.from_pandas(test_ukr_unlabeled_df[['sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "7280742a295b4e77bde221c820321f9f",
      "9d18ae7c77e14c7a888f788b267bf6eb",
      "277519c04de44deba881bf6e8b726224",
      "dc9bb26ae8ab4e218f824d090cb9daa8",
      "5350d1158b554b5fa3dba9b9d7fddedc",
      "b305b48f61b44b52b729ebc7687089b2",
      "dce7901ef3ca4217b67b624d6a1da217",
      "6c5a5c85b4f44501b670e6540577a39b",
      "90b513d6de884eefbbf619c6dc4b5948",
      "1aa4d182ad8449ab995b8ef328001bcd",
      "5c053e989b914b3ab2e8550d9f0799b2",
      "dd266c6ed4cc4bfb949b30184ee1d2c1",
      "0594ef8c109d46f7a8dc7d1cecad135c",
      "e0d2be33543943b0bc812f3c051d8959",
      "507f7b394175496eb27b194d40603255",
      "b024b4008d114222a6b2887a4489c519",
      "bc694c5733d149a5901ece4d67108c8f",
      "10edbba740b94e8d922b34ad7f6e4efe",
      "8aa28e3bc72348919f8f41c6d8fce7de",
      "ed4117af9284497c9742ec2f5fdd435c",
      "3993f3a8069244d48c72d578c7ba3b82",
      "a95f1488fca946a7ad5db2728711f0cf",
      "ee8e9ee2f3d34256878cbd7adcd5f34e",
      "aaa78d8786c946f2bee6eb55bb8bc8b1",
      "2f72506a19c844d29e1c745d32f549f9",
      "90f2cdf60ce445399553d6da92dc2c4d",
      "9ef5dec51a474e29978dab58f670434f",
      "08134ec8829045f99a57352bc744aa37",
      "e9e27581151c427ebed9679f4d33835a",
      "c1c92f58b3544f7392fda330391d3c03",
      "4e5deea4ac024f2ba33d79454985e0c0",
      "2d007747942947d1870d4adf831bcbcd",
      "a815448326034e529bcda9a34d7d4a00",
      "fdec10fbf93c4ac6b05b8c3c9c16ce1e",
      "9b55c4875f10449c8f7639deeabdbe6c",
      "89d19b3af31144b9bf4ac0df0eb4f18f",
      "2ffc13d94f5e4c7cb958442eeaa21d74",
      "260c296a36e1446baa108111171cc6c0",
      "8155b0a636634fd08f7d26932acdf13a",
      "968407e0ef0d493cafd26317229f78c0",
      "f4f57984e58f420197785c43f6eb95a0",
      "39ee25ddee4a4730b7c5f7e4a7e3e036",
      "c81e35489c964a7cab80a5a40a1d7e31",
      "7bb2c2b35a974b7a9c5f95ca44111a83",
      "a3d087566041403c8c326495da43fb25",
      "70aa7f379fb246ed9440555f4747f28a",
      "20a7fca23c594a04be808bef16777a20",
      "6aa035554d264c2ebb944e6fba217518",
      "52a4bd0637d74be7bfe1726c0da81b45",
      "689781bbd6744d6eaee78b2a0b1f148a",
      "fb20911d49a14604bdbb1b9b752dd7b4",
      "a16c1769c5c0464d9c1363161f8fefcf",
      "376f959b6e544c47b59d40ac4a53e447",
      "2739b00ef63847819da2545d438bdd29",
      "b569f72d25df4aec9edf2fd412cd07b0",
      "109e0be759e44244997e083d150dc10a",
      "3f7c105a45714811a46280d3de7f36b8",
      "41eeb53a505e44d290c759d6908d5440",
      "9ca10068e3c84ea3bc5e0a6dd35d3dde",
      "5c174d763c0a4309b70e6f5898ad7631",
      "ab98a2bf63774ec58c15c6dec78eb8bf",
      "0544c1844f1b43909a80d4e9c8226afe",
      "c8ccdc0c0ff44e3da891e2b997fbe2a2",
      "b0429b92c27740e18c9b727c97164dcf",
      "2604448df10a4a3cabfa993ae5c08ab0",
      "38ad614269ac4ec48cf5d54adeb598dc",
      "98089edc36944fe491c14adc8dc85412",
      "9f01f479efe5416d85f0932c1ca30247",
      "91e519caaba24ac5a08386d7cacaa9a9",
      "dc896ec89a4d4541bb541607f6a05a97",
      "00aa2569e4314f1ba13dc7a557ac3fd3",
      "a9ac5ece3b4c4a058fa6acb4cec0c58e",
      "dc48aaadb4be4100b10e37cf326b74c8",
      "102063f8b3c64984acccf27b5f3578a2",
      "e047d9f6fd4a48bbbd5ad6b2a9804c42",
      "369fb4fbb4d545d79f201f6fc79239cb",
      "111984c09c1b470b9b48bf6fed0b90fa",
      "7f1ae64e0fcc451e8531ba2303cc9785",
      "701695f0827949c4b1a6987a6f0edc58",
      "021967937dd6434eb7649169e3defc48",
      "cbdd05dc4bcb4a8abc8070110db50593",
      "ecd0f2bb5e6a4ee99322212eac856991",
      "03de42711c1d430aa1421ba988d55cf0",
      "8aeaae218782445984bba179fe42096b",
      "6450da943e164fee9d62833d3f2ea58f",
      "683b20f458564e1ba7d2635947e8c6d3",
      "21b6c927492c484fba74ba872c0f85ce",
      "83c0b8a5e68d425d9c127ec8557c6658"
     ]
    },
    "id": "Gb9zJ3ahQ92D",
    "outputId": "4e0c22f1-c18d-4b6b-8691-cf0703a2151a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7280742a295b4e77bde221c820321f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd266c6ed4cc4bfb949b30184ee1d2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8e9ee2f3d34256878cbd7adcd5f34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec10fbf93c4ac6b05b8c3c9c16ce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d087566041403c8c326495da43fb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109e0be759e44244997e083d150dc10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98089edc36944fe491c14adc8dc85412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1ae64e0fcc451e8531ba2303cc9785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "test_gr_ds   = test_gr_ds.map(tokenize, batched=True)\n",
    "test_pol_ds  = test_pol_ds.map(tokenize, batched=True)\n",
    "test_ro_ds   = test_ro_ds.map(tokenize, batched=True)\n",
    "test_ukr_ds  = test_ukr_ds.map(tokenize, batched=True)\n",
    "test_gr_unlabeled_ds = test_gr_unlabeled_ds.map(tokenize, batched=True)\n",
    "test_pol_unlabeled_ds = test_pol_unlabeled_ds.map(tokenize, batched=True)\n",
    "test_ro_unlabeled_ds = test_ro_unlabeled_ds.map(tokenize, batched=True)\n",
    "test_ukr_unlabeled_ds = test_ukr_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "test_gr_ds    = test_gr_ds.remove_columns([c for c in test_gr_ds.column_names if c not in cols])\n",
    "test_pol_ds   = test_pol_ds.remove_columns([c for c in test_pol_ds.column_names if c not in cols])\n",
    "test_ro_ds    = test_ro_ds.remove_columns([c for c in test_ro_ds.column_names if c not in cols])\n",
    "test_ukr_ds   = test_ukr_ds.remove_columns([c for c in test_ukr_ds.column_names if c not in cols])\n",
    "test_gr_unlabeled_ds = test_gr_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_gr_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])\n",
    "test_pol_unlabeled_ds = test_pol_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_pol_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])\n",
    "test_ro_unlabeled_ds = test_ro_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_ro_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])\n",
    "test_ukr_unlabeled_ds = test_ukr_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_ukr_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3sm5PN0QkQh"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR7r2WjmEhbN"
   },
   "source": [
    "##Load best multilingual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dwr6eCn0QSQg",
    "outputId": "813ec726-63d2-42aa-e783-99ef2ea7f501"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-9-793152308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Multilingual_balanced\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "158b33c7fb53401b91123d21d977b3b0",
      "b26dd3305e85453cb0c5473c5a31bf57",
      "f2ce189427204b308fd7a5f4ac780ba6",
      "2497402540084544b81a6d592fe3a824",
      "fea55a79351c45b29abf42d0db582063",
      "b1d6a7972f8c487b9fc67fb33d6a9cc6",
      "269b9a062e774eb2933825d482d8ddc7",
      "4617701489fd47598c7d9649aadd76e2",
      "bf25cff20c2c4f4fb2ff14898a573892",
      "f13d6e1af70d4e249f610f8c4ad6d789",
      "999a58b82a444584a6ffffc2830d3c3a"
     ]
    },
    "id": "FRpC18kjYtXp",
    "outputId": "fb1d6e6e-f039-4d8f-9d38-c51ad620fdbb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158b33c7fb53401b91123d21d977b3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_gr_ds = test_gr_ds.filter(lambda x: x[\"labels\"] in [0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBCQhUwgEtG_"
   },
   "source": [
    "##Greek result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6y7CkRAEvVJ"
   },
   "source": [
    "Result for test data(labeled): **Macro F1:  0.77467**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "s-rYicaNQoPP",
    "outputId": "4c840950-394f-4ebd-9436-81765eae332b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmehreganmohseni\u001b[0m (\u001b[33mmehreganmohseni-universit-di-bologna\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250628_023637-cnwp4pp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/cnwp4pp6' target=\"_blank\">tmp_trainer</a></strong> to <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface' target=\"_blank\">https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/cnwp4pp6' target=\"_blank\">https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/cnwp4pp6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.92766, Recall: 0.92373, F1: 0.92569\n",
      "SUBJ – Precision: 0.61702, Recall: 0.63043, F1: 0.62366\n",
      "Macro‐F1: 0.77467\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_gr_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xti7V6k3R1KH",
    "outputId": "6679c52a-79b7-4050-e298-375bccf215f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/greek_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_gr_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_gr_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/greek_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNUHcB2cE79B"
   },
   "source": [
    "##Romanian result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN9syuhyE1bE"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.72798**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "gS29yQMuSFKz",
    "outputId": "e084eaa3-d2da-46bf-8000-3bf3c721d3f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.92000, Recall: 0.74675, F1: 0.82437\n",
      "SUBJ – Precision: 0.51852, Recall: 0.80769, F1: 0.63158\n",
      "Macro‐F1: 0.72798\n"
     ]
    }
   ],
   "source": [
    "# 4) Evaluate on your labeled test set\n",
    "metrics = trainer.evaluate(test_ro_ds)\n",
    "\n",
    "# 5) Print out the per-class and macro metrics\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AaE7vLNBR7hu",
    "outputId": "71b9226b-eb3b-451c-a92b-49720b8251f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/romainian_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_ro_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_ro_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/romainian_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-pM7R06FgKj"
   },
   "source": [
    "##Ukrainian result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKUdMVTyE2Ql"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.64025**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "HtswshKDSGAz",
    "outputId": "d26e00ff-2ffd-447f-8b31-0935d1ebb5cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.82039, Recall: 0.77169, F1: 0.79529\n",
      "SUBJ – Precision: 0.45055, Recall: 0.52564, F1: 0.48521\n",
      "Macro‐F1: 0.64025\n"
     ]
    }
   ],
   "source": [
    "# 4) Evaluate on your labeled test set\n",
    "metrics = trainer.evaluate(test_ukr_ds)\n",
    "\n",
    "# 5) Print out the per-class and macro metrics\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AmKLLDiUR8mG",
    "outputId": "d7e08e89-6744-4bd9-990a-e5fe0ea794fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/ukrainian_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_out = trainer.predict(test_ukr_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_ukr_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/ukrainian_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5zGJNkzFwh9"
   },
   "source": [
    "##Polish result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4RyQfTcE3Uh"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.64251**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "YepWjFESSGyH",
    "outputId": "fe5126d6-3fd0-459b-cdc7-a6c581d5b73c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.64041, Recall: 0.98421, F1: 0.77593\n",
      "SUBJ – Precision: 0.94915, Recall: 0.34783, F1: 0.50909\n",
      "Macro‐F1: 0.64251\n"
     ]
    }
   ],
   "source": [
    "# 4) Evaluate on your labeled test set\n",
    "metrics = trainer.evaluate(test_pol_ds)\n",
    "\n",
    "# 5) Print out the per-class and macro metrics\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NSeQilddR9T3",
    "outputId": "8cdc5564-5421-47d3-9187-3e48e415ced6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/polish_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_out = trainer.predict(test_pol_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_pol_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/zeroshot/polish_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
