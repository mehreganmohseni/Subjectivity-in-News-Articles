{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbVu6-tt6oo_"
   },
   "source": [
    "##Monolingual_German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1s_3uGOyWHw",
    "outputId": "aab2780f-bfa3-4b08-c154-cb236e5c3f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cVXzdYXLdvF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZpAt4M4yA_4"
   },
   "source": [
    "##Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP5PEFU4yjto"
   },
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/data/german'\n",
    "train_path = f'{base_dir}/train_de.tsv'\n",
    "dev_path   = f'{base_dir}/dev_de.tsv'\n",
    "dev_test_path = f'{base_dir}/dev_test_de.tsv'\n",
    "test_path = f'{base_dir}/test_de_labeled.tsv'\n",
    "test_unlabeled_path = f'{base_dir}/test_de_unlabeled.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvRILJGrNOyQ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df   = pd.read_csv(dev_path, sep='\\t')\n",
    "dev_test_df = pd.read_csv(dev_test_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "test_unlabeled_df = pd.read_csv(test_unlabeled_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nVjnTOvyEpD"
   },
   "source": [
    "##Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Wsl9Jgtdlfw",
    "outputId": "6e633c3a-bc1f-424e-afc0-203f5710cefe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped classes: {0: 'OBJ', 1: 'SUBJ'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['label_id']    = le.fit_transform(train_df['label'])\n",
    "dev_df['label_id']      = le.transform(dev_df['label'])\n",
    "dev_test_df['label_id'] = le.transform(dev_test_df['label'])\n",
    "test_df['label_id']     = le.transform(test_df['label'])\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.rename(columns={'label_id':'labels'}, inplace=True)\n",
    "\n",
    "print(\"Mapped classes:\", dict(enumerate(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl61hFt2dpZY"
   },
   "outputs": [],
   "source": [
    "train_ds    = Dataset.from_pandas(train_df[['sentence','labels']])\n",
    "dev_ds      = Dataset.from_pandas(dev_df[['sentence','labels']])\n",
    "dev_test_ds = Dataset.from_pandas(dev_test_df[['sentence','labels']])\n",
    "test_ds = Dataset.from_pandas(test_df[['sentence','labels']])\n",
    "test_unlabeled_ds = Dataset.from_pandas(test_unlabeled_df[['sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "252vkRToOaYH",
    "outputId": "707a6bf6-3c36-4ecf-f633-dcc6fa49c020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts → OBJ: 492, SUBJ: 308\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(train_ds['labels'])\n",
    "n_obj, n_subj = counts[0], counts[1]\n",
    "print(f\"Original counts → OBJ: {n_obj}, SUBJ: {n_subj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIar3kimyKWm"
   },
   "source": [
    "#First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_X_GJfGyXyu"
   },
   "source": [
    "For tokenize data, we use the **dbmdz/bert-base-german-cased** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "d2b61e5cff59479e9f745e55f4ce7d31",
      "6587b39b158b41c18494bb8b71dbcc87",
      "0af482ee2ded4d588f7b14314acf051c",
      "df238bcc79364a93a30ecf116482b37c",
      "853d4a681d5447478c0027f728fda8e0",
      "fd9f05dac8b54c2298629b45985e259d",
      "e5366304f8134685bef22349ebf6b0bc",
      "218d9898b28b4bf796c6013354051d2a",
      "529b4107f0aa4cf391851ca00c0a94ef",
      "b626d98b724f4155adab61fe2797076a",
      "1064a2205458432297b3bc188581ef74",
      "81dcb9f795774ed1835e99eb09513a75",
      "4ff370d3ea524c2aaa9793283673a7d6",
      "a59f2c50851444e0be2cdfcad53be09d",
      "f720ab255ea0453d8a4139acf7f9067c",
      "c5a4e94e2adf48eda599060ae8ceb6a8",
      "12cf2e1dec9846509b7723b948e205ec",
      "07e006b9637c472287e719e86f48943b",
      "00be0a4ddc614fd08da7c04598c21670",
      "0fa379c3cbb94b2e9778947e8d225578",
      "8819d54fddbe4b0db1fd609fadc6f8a3",
      "d61fac14271a420eb44a8efbeaf97a52",
      "5841a5b270e24487895f041551e76991",
      "1f41a230c7d44b36b3986544ac62372f",
      "da7fcf2b5e9d48e79ada640f51e385b7",
      "a509d770d7f74d2b95439a0c0bd17e1f",
      "9aee9c27ba084288ab25749952de5b44",
      "47d3c260fdf94b4883d14595257cbbb2",
      "c76d872829fb4824889361d2f900facc",
      "019c6dfff3ef4821bc783c5dbedd9fed",
      "1aa3b66d842c480fb8413e59968e9b93",
      "0c333a1bbd9040138949acb8821f1c36",
      "92581583972947e59628eef4cc57e3f0",
      "d750caa3ae274086a53181cc4b54f070",
      "dca0fe20a89c48d998fc3e85aca14421",
      "c3239df1dd4e4a049332580d598f1ebf",
      "bb324d580234468f88637e491c97bd22",
      "85429dea17b443bbb3f87c8c18961a7e",
      "e1f8b69a6e484e56b304185fe5847419",
      "178cf197cf5c4dea9362d2d0fcb4acb3",
      "3cd7b935e817464c800155c237a8449b",
      "506fb86185fa4a69804cf5d1795937d9",
      "17486563a8f04f5197dacc77e02d0922",
      "c1b8df8672a444e7905d0c35851dce44",
      "297156c11fcc435bbaba232608323cc3",
      "2d73797c69a0403d9fea38977ecb033a",
      "04de5b0ef5da449eb6f31c1fff1e7472",
      "381cbe45064a4cbe90fe719b50072e18",
      "43fc08892bf5489c9b90381784ab1571",
      "bf6bdf7a874541bf8ad190c1fc0400dc",
      "401e35df9d2b41aba78a6f875bd4de9c",
      "2b92472659be4706bbb1e014aa24c61c",
      "8f7232027cf0440199203d86eaf2a694",
      "c9594da110b14b30a7c5a9125682fabc",
      "29c862b99da5432ca25d988ad213daf9"
     ]
    },
    "id": "haRpwKSrdvcv",
    "outputId": "7a8fdbb1-a5ca-40e9-8940-731ab7db2c28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b61e5cff59479e9f745e55f4ce7d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dcb9f795774ed1835e99eb09513a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5841a5b270e24487895f041551e76991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d750caa3ae274086a53181cc4b54f070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297156c11fcc435bbaba232608323cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"dbmdz/bert-base-german-cased\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pormYuJWyjw9"
   },
   "source": [
    " Define a data collator for dynamic padding and a metrics function to compute per-class precision, recall, F1, and macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVzqVQowfU-g"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuvtfRbBynhf"
   },
   "source": [
    " Use WeightedRandomSampler to balance class sampling in each batch, and customize Trainer to use this sampler during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNwHEoUJXzu"
   },
   "outputs": [],
   "source": [
    "# Extract train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePB5UtrQyyTi"
   },
   "source": [
    " Initialize model **(dbmdz/bert-base-german-cased)** and training configuration with gradient checkpointing and early stopping.\n",
    "\n",
    " Uses a custom SamplerTrainer to address class imbalance, and selects the best model based on macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRxFkq-Mfac7",
    "outputId": "4146a6db-3132-4d81-b5c3-e6e725fbe1ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-92-2093088531.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results_de\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 2e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    gradient_accumulation_steps   = 4,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 6,\n",
    "    weight_decay              = 0.1,\n",
    "    warmup_ratio              = 0.1,\n",
    "    lr_scheduler_type         = \"linear\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_de',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckb6HxkszcLM"
   },
   "source": [
    "Train the model and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ss4SWIqlU_Iu",
    "outputId": "6ce68ca4-e4e2-41f6-9554-2c226e25ca4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 03:40, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.643800</td>\n",
       "      <td>0.653741</td>\n",
       "      <td>0.631365</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.564669</td>\n",
       "      <td>0.664193</td>\n",
       "      <td>0.486989</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>0.627808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.563025</td>\n",
       "      <td>0.733198</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.665615</td>\n",
       "      <td>0.763110</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.856322</td>\n",
       "      <td>0.694639</td>\n",
       "      <td>0.728875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.543764</td>\n",
       "      <td>0.775967</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.640351</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.726368</td>\n",
       "      <td>0.768356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0.523679</td>\n",
       "      <td>0.796334</td>\n",
       "      <td>0.851133</td>\n",
       "      <td>0.829653</td>\n",
       "      <td>0.840256</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.779678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>0.792261</td>\n",
       "      <td>0.879859</td>\n",
       "      <td>0.785489</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.732984</td>\n",
       "      <td>0.781492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.544440</td>\n",
       "      <td>0.800407</td>\n",
       "      <td>0.859016</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.842444</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.752874</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.785111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WI9BxTC_zi27"
   },
   "source": [
    "training and evaluation loss logs for each epoch, then evaluate and display final macro F1 scores on the train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "CnmfNKrj39dr",
    "outputId": "d3369178-3ede-4f8a-af03-c3f165e3fe34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6438, 'grad_norm': 1.2293331623077393, 'learning_rate': 1.885714285714286e-05, 'epoch': 1.0, 'step': 13}\n",
      "{'eval_loss': 0.6537414193153381, 'eval_accuracy': 0.6313645621181263, 'eval_precision_OBJ': 0.8063063063063063, 'eval_recall_OBJ': 0.5646687697160884, 'eval_f1_OBJ': 0.6641929499072357, 'eval_precision_SUBJ': 0.48698884758364314, 'eval_recall_SUBJ': 0.7528735632183908, 'eval_f1_SUBJ': 0.5914221218961625, 'eval_macro_f1': 0.627807535901699, 'eval_runtime': 0.6472, 'eval_samples_per_second': 758.659, 'eval_steps_per_second': 12.361, 'epoch': 1.0, 'step': 13}\n",
      "{'loss': 0.5236, 'grad_norm': 1.687044382095337, 'learning_rate': 1.5142857142857144e-05, 'epoch': 2.0, 'step': 26}\n",
      "{'eval_loss': 0.5630254149436951, 'eval_accuracy': 0.7331975560081466, 'eval_precision_OBJ': 0.8940677966101694, 'eval_recall_OBJ': 0.6656151419558359, 'eval_f1_OBJ': 0.7631103074141049, 'eval_precision_SUBJ': 0.5843137254901961, 'eval_recall_SUBJ': 0.8563218390804598, 'eval_f1_SUBJ': 0.6946386946386947, 'eval_macro_f1': 0.7288745010263997, 'eval_runtime': 0.636, 'eval_samples_per_second': 772.009, 'eval_steps_per_second': 12.579, 'epoch': 2.0, 'step': 26}\n",
      "{'loss': 0.4382, 'grad_norm': 1.9563785791397095, 'learning_rate': 1.1428571428571429e-05, 'epoch': 3.0, 'step': 39}\n",
      "{'eval_loss': 0.5437639951705933, 'eval_accuracy': 0.7759674134419552, 'eval_precision_OBJ': 0.8935361216730038, 'eval_recall_OBJ': 0.7413249211356467, 'eval_f1_OBJ': 0.8103448275862069, 'eval_precision_SUBJ': 0.6403508771929824, 'eval_recall_SUBJ': 0.8390804597701149, 'eval_f1_SUBJ': 0.7263681592039801, 'eval_macro_f1': 0.7683564933950935, 'eval_runtime': 0.6271, 'eval_samples_per_second': 782.908, 'eval_steps_per_second': 12.756, 'epoch': 3.0, 'step': 39}\n",
      "{'loss': 0.3483, 'grad_norm': 3.1052255630493164, 'learning_rate': 7.714285714285716e-06, 'epoch': 4.0, 'step': 52}\n",
      "{'eval_loss': 0.5236787796020508, 'eval_accuracy': 0.7963340122199593, 'eval_precision_OBJ': 0.8511326860841424, 'eval_recall_OBJ': 0.8296529968454258, 'eval_f1_OBJ': 0.8402555910543131, 'eval_precision_SUBJ': 0.7032967032967034, 'eval_recall_SUBJ': 0.735632183908046, 'eval_f1_SUBJ': 0.7191011235955056, 'eval_macro_f1': 0.7796783573249093, 'eval_runtime': 0.6753, 'eval_samples_per_second': 727.052, 'eval_steps_per_second': 11.846, 'epoch': 4.0, 'step': 52}\n",
      "{'loss': 0.3155, 'grad_norm': 2.398850202560425, 'learning_rate': 4.000000000000001e-06, 'epoch': 5.0, 'step': 65}\n",
      "{'eval_loss': 0.5539025068283081, 'eval_accuracy': 0.7922606924643585, 'eval_precision_OBJ': 0.8798586572438163, 'eval_recall_OBJ': 0.7854889589905363, 'eval_f1_OBJ': 0.83, 'eval_precision_SUBJ': 0.6730769230769231, 'eval_recall_SUBJ': 0.8045977011494253, 'eval_f1_SUBJ': 0.7329842931937173, 'eval_macro_f1': 0.7814921465968586, 'eval_runtime': 0.6363, 'eval_samples_per_second': 771.641, 'eval_steps_per_second': 12.573, 'epoch': 5.0, 'step': 65}\n",
      "{'loss': 0.2981, 'grad_norm': 2.842905044555664, 'learning_rate': 2.8571428571428575e-07, 'epoch': 6.0, 'step': 78}\n",
      "{'eval_loss': 0.5444396734237671, 'eval_accuracy': 0.8004073319755601, 'eval_precision_OBJ': 0.8590163934426229, 'eval_recall_OBJ': 0.8264984227129337, 'eval_f1_OBJ': 0.842443729903537, 'eval_precision_SUBJ': 0.7043010752688172, 'eval_recall_SUBJ': 0.7528735632183908, 'eval_f1_SUBJ': 0.7277777777777777, 'eval_macro_f1': 0.7851107538406574, 'eval_runtime': 0.6754, 'eval_samples_per_second': 726.955, 'eval_steps_per_second': 11.844, 'epoch': 6.0, 'step': 78}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.9395051256254973\n",
      "Val   macro-F1: 0.7851107538406574\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4GFJ2oezpNE"
   },
   "source": [
    "#Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n50yDmjjHhm5",
    "outputId": "1642877f-c51a-48a2-b280-14090acee0cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-11-116451999.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nbDeo-4zw-p"
   },
   "source": [
    "#Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUzHpIo1zzj8"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.78347**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "zvz6tMoXFFDy",
    "outputId": "127d08b5-ab30-44a9-dd64-53f952961d24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmehreganmohseni\u001b[0m (\u001b[33mmehreganmohseni-universit-di-bologna\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250626_142855-r8h1jjfo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/r8h1jjfo' target=\"_blank\">tmp_trainer</a></strong> to <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface' target=\"_blank\">https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/r8h1jjfo' target=\"_blank\">https://wandb.ai/mehreganmohseni-universit-di-bologna/huggingface/runs/r8h1jjfo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.84100, Recall: 0.87773, F1: 0.85897\n",
      "SUBJ – Precision: 0.74074, Recall: 0.67797, F1: 0.70796\n",
      "Macro‐F1: 0.78347\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2_rFaBmz-x-"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "aWL_-Eoscm1u",
    "outputId": "d730b047-9774-46b8-a013-633a595e6dc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.91667, Recall: 0.86275, F1: 0.88889\n",
      "SUBJ – Precision: 0.73750, Recall: 0.83099, F1: 0.78146\n",
      "Macro‐F1: 0.83517\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPmdOLZI0ENW"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Obvi8k-4HrZc",
    "outputId": "d25b033f-23fb-4f97-c602-7e2465085ad7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/german/german_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/german/german_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE2hO5lAghp3"
   },
   "source": [
    "#Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GihRqwHJ0Tw0"
   },
   "source": [
    "For tokenize data, we use the **mdeberta-v3-base** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "7b73d9301da04bc5ac51a1cbfdb15611",
      "5b554c067de848469175f27863da0709",
      "2bcc204ec5574db7ab6431955e239153",
      "e37cd92d29174e218e1334da01a9d961",
      "5bc039939c6345bd98b7b64118bc0cea",
      "a3ade7f230284641abebd0197fc1e966",
      "ca67061e03754a92a957b2aabb8c51ef",
      "9b01389415e84f0fb11259c187386fa5",
      "173a87bd9b70442ebfbfd85dda7ef3f1",
      "9f5bef82fee7450ebc962fe123a9f265",
      "3871f84a1cda4d2e9bd59097cfc46f90",
      "778d586cbe394d2d979a93b8255505fc",
      "34a09052b3f9476fb7eab0509f739814",
      "8500a00003f546cfba3acfe36b23f390",
      "022a7db39a7844b68df18ea20716a980",
      "2cbb81f129984d94b27c7d347b59190f",
      "a67db2b153b3436dbbf9c6db23a8b339",
      "69b5a05b92a34b34997cacdb9bf2a116",
      "f4869b186567417cbc786913f4b93d3f",
      "a99e3a9988264d7792230ff294eef0fc",
      "afa978582e034425bf92bf14d474d613",
      "a4e4d90d726b4632a051b24b12124792",
      "d92f4163789b4f2b9e2a42ecfb7d2078",
      "8db57f516d624c99bfe308054e0d2ad5",
      "83e0942e20684a85b504d7658bc9b3e6",
      "ae74f32f93474417b497ea601fd50e20",
      "40e8d66c24854bc4bad727d5cb5c2395",
      "ff838caf21f84702a1755af0282b843d",
      "3061d1b92d0d431fa3c30515beec9eb5",
      "fca33507e4054699b5ace4a94bb8e4f4",
      "a7bfb341bb6f41e59d029e35a9d06dd2",
      "0160d8fa483648549080e8b3319566a6",
      "944d6b7011a740feaa6fb268913716b0",
      "c155531580a949b1b2594284cfee519f",
      "c3b5b22852b847b799bbb8a61e2fafa5",
      "f79658dda61649bdaeb9a984ed9d651f",
      "f7f0e6f4a00744489f84eccd20cdb403",
      "b3b759afc6af4f55809464b9b9a7ec1d",
      "af66159a93d74741ab12e4430e0840ea",
      "968596904be547619175eb18f770a7c2",
      "9bac881bc1034fc0ad319b4aa513358d",
      "be819f5a8447469da813e064c253092f",
      "f068c409d6424cbea81e573e6388129f",
      "2016b0036f5042258748685147315ff9",
      "51f719f12eeb40fcb685313e1c027962",
      "124418e87fe64d55a06f818787de7b7d",
      "122d5099553747e1a607c6d89e898d52",
      "6b57945e77494cc4a315d6f842ab3dc1",
      "e2dbfb06d4ad46559d443d6c09cbbeb1",
      "39178d2c02b14776b8d6448cd1405136",
      "4c7e7b4a71b44f3e81a8f44d9e3728d0",
      "5571a7c6c9bf4c9aa06fcb1edc3c03ed",
      "f76786f0555a4e37b3157ced5216a9e2",
      "bd144e1b50cc43619b6cb8d89b9e2bde",
      "5ac28f3a950646c1b01b98a6b035ef7d"
     ]
    },
    "id": "VFRuxx1-gklR",
    "outputId": "f5bca38e-2f41-4f74-da64-50a7ed59e2cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b73d9301da04bc5ac51a1cbfdb15611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d586cbe394d2d979a93b8255505fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92f4163789b4f2b9e2a42ecfb7d2078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c155531580a949b1b2594284cfee519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f719f12eeb40fcb685313e1c027962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm09_K7Ugtyf"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_sjUXk4g4wq"
   },
   "outputs": [],
   "source": [
    "train_labels = train_ds[\"labels\"]\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqHtr5LJhDF1",
    "outputId": "4e2cbf8c-a022-4a5c-d74f-886ab5ef3a65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-38-124158083.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results1_de\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 2e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    gradient_accumulation_steps   = 4,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 6,\n",
    "    weight_decay              = 0.1,\n",
    "    warmup_ratio              = 0.1,\n",
    "    lr_scheduler_type         = \"linear\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_de',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "279l_z-fhLyP",
    "outputId": "cb73d08b-7bb8-41fa-e3c3-adde18605f4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/78 08:26 < 01:44, 0.12 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>0.703300</td>\n",
       "      <td>0.354379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.523308</td>\n",
       "      <td>0.261654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>0.644441</td>\n",
       "      <td>0.657841</td>\n",
       "      <td>0.654244</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.433462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.564104</td>\n",
       "      <td>0.749491</td>\n",
       "      <td>0.814935</td>\n",
       "      <td>0.791798</td>\n",
       "      <td>0.803200</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.729331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.488500</td>\n",
       "      <td>0.520804</td>\n",
       "      <td>0.802444</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.870662</td>\n",
       "      <td>0.850539</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.708709</td>\n",
       "      <td>0.779624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.522441</td>\n",
       "      <td>0.790224</td>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.817035</td>\n",
       "      <td>0.834138</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.714681</td>\n",
       "      <td>0.774410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german1\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german1\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "zNNjoCq7hY77",
    "outputId": "81b5e7c0-d75b-4786-ae91-fbf41d85e31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6647, 'grad_norm': 0.47663822770118713, 'learning_rate': 1.885714285714286e-05, 'epoch': 1.0, 'step': 13}\n",
      "{'eval_loss': 0.7032999992370605, 'eval_accuracy': 0.3543788187372709, 'eval_precision_OBJ': 0.0, 'eval_recall_OBJ': 0.0, 'eval_f1_OBJ': 0.0, 'eval_precision_SUBJ': 0.3543788187372709, 'eval_recall_SUBJ': 1.0, 'eval_f1_SUBJ': 0.5233082706766917, 'eval_macro_f1': 0.26165413533834586, 'eval_runtime': 1.2899, 'eval_samples_per_second': 380.655, 'eval_steps_per_second': 6.202, 'epoch': 1.0, 'step': 13}\n",
      "{'loss': 0.6558, 'grad_norm': 0.9440619945526123, 'learning_rate': 1.5142857142857144e-05, 'epoch': 2.0, 'step': 26}\n",
      "{'eval_loss': 0.6444412469863892, 'eval_accuracy': 0.6578411405295316, 'eval_precision_OBJ': 0.6542443064182195, 'eval_recall_OBJ': 0.9968454258675079, 'eval_f1_OBJ': 0.79, 'eval_precision_SUBJ': 0.875, 'eval_recall_SUBJ': 0.040229885057471264, 'eval_f1_SUBJ': 0.07692307692307693, 'eval_macro_f1': 0.43346153846153845, 'eval_runtime': 1.0826, 'eval_samples_per_second': 453.542, 'eval_steps_per_second': 7.39, 'epoch': 2.0, 'step': 26}\n",
      "{'loss': 0.5897, 'grad_norm': 1.6165778636932373, 'learning_rate': 1.1428571428571429e-05, 'epoch': 3.0, 'step': 39}\n",
      "{'eval_loss': 0.5641041398048401, 'eval_accuracy': 0.7494908350305499, 'eval_precision_OBJ': 0.814935064935065, 'eval_recall_OBJ': 0.7917981072555205, 'eval_f1_OBJ': 0.8032, 'eval_precision_SUBJ': 0.639344262295082, 'eval_recall_SUBJ': 0.6724137931034483, 'eval_f1_SUBJ': 0.6554621848739496, 'eval_macro_f1': 0.7293310924369748, 'eval_runtime': 1.0659, 'eval_samples_per_second': 460.641, 'eval_steps_per_second': 7.505, 'epoch': 3.0, 'step': 39}\n",
      "{'loss': 0.4885, 'grad_norm': 3.4957807064056396, 'learning_rate': 7.714285714285716e-06, 'epoch': 4.0, 'step': 52}\n",
      "{'eval_loss': 0.5208044052124023, 'eval_accuracy': 0.8024439918533605, 'eval_precision_OBJ': 0.8313253012048193, 'eval_recall_OBJ': 0.8706624605678234, 'eval_f1_OBJ': 0.8505392912172574, 'eval_precision_SUBJ': 0.7421383647798742, 'eval_recall_SUBJ': 0.6781609195402298, 'eval_f1_SUBJ': 0.7087087087087087, 'eval_macro_f1': 0.779623999962983, 'eval_runtime': 1.0964, 'eval_samples_per_second': 447.811, 'eval_steps_per_second': 7.296, 'epoch': 4.0, 'step': 52}\n",
      "{'loss': 0.432, 'grad_norm': 3.165870189666748, 'learning_rate': 4.000000000000001e-06, 'epoch': 5.0, 'step': 65}\n",
      "{'eval_loss': 0.5224412083625793, 'eval_accuracy': 0.790224032586558, 'eval_precision_OBJ': 0.8519736842105263, 'eval_recall_OBJ': 0.8170347003154574, 'eval_f1_OBJ': 0.8341384863123994, 'eval_precision_SUBJ': 0.6898395721925134, 'eval_recall_SUBJ': 0.7413793103448276, 'eval_f1_SUBJ': 0.7146814404432132, 'eval_macro_f1': 0.7744099633778063, 'eval_runtime': 1.0313, 'eval_samples_per_second': 476.094, 'eval_steps_per_second': 7.757, 'epoch': 5.0, 'step': 65}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.8368940345998557\n",
      "Val   macro-F1: 0.779623999962983\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSd3iWjXhbtj",
    "outputId": "285ddd42-c221-4273-fcda-c2c48998cf10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-42-910838007.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_german1\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "443yDnHd1fhA"
   },
   "source": [
    "#Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p43l5b9D1bWS"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.75289**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "XncAIwT5hhNY",
    "outputId": "f22189ff-a915-4402-b9af-60a287b9246d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.82553, Recall: 0.84716, F1: 0.83621\n",
      "SUBJ – Precision: 0.68750, Recall: 0.65254, F1: 0.66957\n",
      "Macro‐F1: 0.75289\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oeqed_ke1mXz"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "ADfVdG3fhkQT",
    "outputId": "fc8c1ba3-3513-4038-9db0-e0aac8400481"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.88652, Recall: 0.81699, F1: 0.85034\n",
      "SUBJ – Precision: 0.66265, Recall: 0.77465, F1: 0.71429\n",
      "Macro‐F1: 0.78231\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWzs6my41yO3"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xZ-HGpMuhndW",
    "outputId": "a5e5eecf-65f5-48cf-8fd7-f42cd76e0d06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/german/german_predictions1.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/german/german_predictions1.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
