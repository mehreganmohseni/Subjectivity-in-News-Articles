{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbVu6-tt6oo_"
   },
   "source": [
    "##Monolingual_Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1s_3uGOyWHw",
    "outputId": "1b2d6c08-8167-46d5-c634-f8723cc6ce7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cVXzdYXLdvF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaFt1L13AJMU"
   },
   "source": [
    "##Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP5PEFU4yjto"
   },
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/data/arabic'\n",
    "train_path = f'{base_dir}/train_ar.tsv'\n",
    "dev_path   = f'{base_dir}/dev_ar.tsv'\n",
    "dev_test_path = f'{base_dir}/dev_test_ar.tsv'\n",
    "test_path = f'{base_dir}/test_ar_labeled.tsv'\n",
    "test_unlabeled_path = f'{base_dir}/test_ar_unlabeled.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvRILJGrNOyQ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df   = pd.read_csv(dev_path, sep='\\t')\n",
    "dev_test_df = pd.read_csv(dev_test_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "test_unlabeled_df = pd.read_csv(test_unlabeled_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul3_b7FYAMM9"
   },
   "source": [
    "##Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Wsl9Jgtdlfw",
    "outputId": "94415310-9850-4805-b084-ff5d54bc88a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped classes: {0: 'OBJ', 1: 'SUBJ'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['label_id']    = le.fit_transform(train_df['label'])\n",
    "dev_df['label_id']      = le.transform(dev_df['label'])\n",
    "dev_test_df['label_id'] = le.transform(dev_test_df['label'])\n",
    "test_df['label_id']     = le.transform(test_df['label'])\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.rename(columns={'label_id':'labels'}, inplace=True)\n",
    "\n",
    "print(\"Mapped classes:\", dict(enumerate(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl61hFt2dpZY"
   },
   "outputs": [],
   "source": [
    "train_ds    = Dataset.from_pandas(train_df[['sentence','labels']])\n",
    "dev_ds      = Dataset.from_pandas(dev_df[['sentence','labels']])\n",
    "dev_test_ds = Dataset.from_pandas(dev_test_df[['sentence','labels']])\n",
    "test_ds = Dataset.from_pandas(test_df[['sentence','labels']])\n",
    "test_unlabeled_ds = Dataset.from_pandas(test_unlabeled_df[['sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "252vkRToOaYH",
    "outputId": "57b10a4f-2b41-4d95-db7b-55641b9065fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts → OBJ: 1391, SUBJ: 1055\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(train_ds['labels'])\n",
    "n_obj, n_subj = counts[0], counts[1]\n",
    "print(f\"Original counts → OBJ: {n_obj}, SUBJ: {n_subj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0YVKr43ATEH"
   },
   "source": [
    "##First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZJJ7kmNAVs1"
   },
   "source": [
    "For tokenize data, we use the **aubmindlab/araelectra-base-discriminator** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461,
     "referenced_widgets": [
      "b967c85882864937b07454fa6d85cec5",
      "a2250836a41f46289da219950005f1af",
      "6fc19b4636c446d89f229dd7397a9727",
      "f0ea5d596e1f418eb4bf94cf911a12f4",
      "8c3f100e7c7c40dd95d614a3ec077717",
      "d6ed5e2ddc5c4728a9a3a4ad86d460c4",
      "f980f95c8c484ac89ae615e746f5679e",
      "e1d4ab1d20764fa79de5ea29c012d16a",
      "943e322c05224be4a6ed56d39f684ae4",
      "4ea80f052e3a492c9b6c93471dc058fc",
      "7584242279c34d77a842e2a9cacd6739",
      "8c7ce62469044f4cb12ca68111d6e113",
      "5a3d4227ba8a4b5c805de1f1ef0f89ea",
      "81e871bb266e4fb5903fb9f74ed014a0",
      "213327c2c667490d8e0483d07c0f8f6e",
      "341fab019d00461585ed22e11a38b5b0",
      "f8cba2ed292d47509fd72932a5dd18f1",
      "354c0d807c624ef48d5528cf0b303f4d",
      "d730e230428b424499e53eca9d21036e",
      "5ccd87eca0f543069515a5d87a4b70f1",
      "5e4a87343841483795cf7c88e7fa5c88",
      "74e7806c47c64427a929591c853605a8",
      "197757cc578f4decb956757d7c43a189",
      "93f72a35bfb74326bb3109806f1a33a6",
      "be15b5cb76f247cb8071f0bd4cbc0d45",
      "aef0c1c96e744e2c82c90e1a33e6ed06",
      "13003cc5706a47f9930308f3f76e95c2",
      "cad91dbcd4154791823a67528b319665",
      "6e5e33e85839455da187366146bf3fb4",
      "08da6fb9329b4dffa77c179a74efd34d",
      "ce29aca3edb2415e91d8563645c385af",
      "1e939005a6d24433819dcc5622874561",
      "263dc3fd4f374e3fa13d034dc06eacba",
      "bf0a088cbce44994936a4857fb56ea43",
      "4c8097fa4de14524ba337fa8e9ee9737",
      "e57c26b950a54384a50337e73bf4c0d4",
      "a37f73011c6144d38bbe97b970bb6def",
      "2b86246dcf3442358bc1e37f8b1516d4",
      "beb2f990c5ec45d198607c45405dfe8c",
      "99ca4f16028a46c68e4a7c83bf9dcb34",
      "a8d3f5f3841347f09db1e19f333eac1b",
      "e1e5b3f835b64a0b9b0f94078d0e0b7c",
      "493d44c1bf6d45908d3defeda01b061e",
      "4d2d01db9a37454186be0f6f6a9edee4",
      "1b023637ed62480296c84e70ed45bfb8",
      "e8ab07b96e1b4cb58de8b4b216bda7fb",
      "4198c732fc4149dcbe893ab59ee1113a",
      "970f72df781d42ffa3fc4aefe8fdfeea",
      "1e08f2884b1b45cbb1fb9f4235dd355e",
      "cbcf3462fe8f4f05bd4f9f47f2cd5c24",
      "a8b4e42489f9483ea9906b65d9eed140",
      "6cbb8addabe5483cace86b178ef4ff6c",
      "ddf60f19083442dba537a0afce644997",
      "c31203020eda41fa830cdad5049c6059",
      "f901c23ed9724e85a7a61353a30c0f6c",
      "8f29ce9005314291ba86fc89b98289b7",
      "597cde4f40ee48519df7abcdda07ed11",
      "669dec05b3b541a68bfa6fe8efae120d",
      "4c32a8ac82ed45fda4454e2fb0a1871b",
      "f299c1202aaa4a08a19b0604da3ac5c2",
      "0ecac84d75344a05b85d0f1fd22d6818",
      "c3e2d1dd0bb2432d8c37c1ee823cd7c4",
      "90cd9e8791fb41d489e54ea343d7a29e",
      "51855f67933f40e2bf0a3818c28ef0dd",
      "ba9513f81f8e435c87cf7b0233fb9992",
      "e0304eef18274ab9ad567fdbc53b831c",
      "b13588c86b3b4fcc83fb883c751c040a",
      "6eeeef26ad99462a996345a7e8f75b4a",
      "d60441ee589b44caba45ca9f7f95ef19",
      "ab2f48ee49e04f6eb8251f8f9839fa39",
      "10afb35c85d742bfac975987b658ac6a",
      "2e275c30a9a54fcfa2a7c946ffa54718",
      "2e7761a021434c349cfffdd451252eaf",
      "e0132bac88464e1396e17d2015e3c138",
      "a0564bd44e824001856a6f549c815d7d",
      "abfb87f3cc7948db94f3a112965316d0",
      "d32708644da9400aa596429489c823cc",
      "6f131fb85f25417c92ee94f2b6b24945",
      "be054f5019b84c619a8a6a62952eecc4",
      "31649aa35711470aa2fccf2c6f099ed8",
      "9609e025aa1c44aa9f53e754d45d6711",
      "1fdb6ee89de34a04bb65854403c03ce3",
      "58b3a43a09c54efd912b431d0af71689",
      "b3bc846a40c24dbf91df5c0978249c2c",
      "cab5f9622f0649b5bad2815924ce473c",
      "454190015ef942febb54c78dcec638e8",
      "de4fa3b020454f05be4ad834627102c7",
      "548e5103ee194492a627f9f23ed8b37f",
      "13a59a031c3b4fd6aadae2dd54b4c607",
      "0586e3f32e2942dea7937c0bb5cb54f1",
      "a4a80e3492ce480188b817e3b0d38ec1",
      "157abc3dc224432e8b98280e2426e8ae",
      "b2f4bb4764604eccafc8af4201bab746",
      "969caa4e961443718586169b0963e94d",
      "cc88d7c6ad27445c951e1fb980d98965",
      "59da00837c1045b08d3ce521a170a2f7",
      "717dd1c069274c8695e7191d6ab6fe7c",
      "493bd9877505442ca97007857e957b96",
      "0efdc4341ba44fd785eadee3da0e7fe2",
      "637f78a4b9ec40999c616c3350ab67ca",
      "ebf9a13b3b32426ca787079da396aad5",
      "c43525f52f4d4ccf89661bb789294c3e",
      "df31c1b3cdd74be29eb14c8c98d96134",
      "7afe0c506d9245a193c8aab28d7a1322",
      "f2f344e7d7b74aa4a6d15663c9b742fa",
      "8c57f2c86dce445197b1adaa77120df8",
      "2ae3c108530043289878f70621a880d9",
      "cedcc784d6d6416098150c39bcb6b499",
      "cad4180a77be41f683f9a50269061cd5",
      "39ce96ba43fc417c89b28508101a414f"
     ]
    },
    "id": "haRpwKSrdvcv",
    "outputId": "6c0d9591-3fcf-42e1-c1c5-a1b4fb74ce52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b967c85882864937b07454fa6d85cec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7ce62469044f4cb12ca68111d6e113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197757cc578f4decb956757d7c43a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a088cbce44994936a4857fb56ea43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b023637ed62480296c84e70ed45bfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f29ce9005314291ba86fc89b98289b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13588c86b3b4fcc83fb883c751c040a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f131fb85f25417c92ee94f2b6b24945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a59a031c3b4fd6aadae2dd54b4c607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637f78a4b9ec40999c616c3350ab67ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"aubmindlab/araelectra-base-discriminator\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq3KbNZ3AqKE"
   },
   "source": [
    " Define a data collator for dynamic padding and a metrics function to compute per-class precision, recall, F1, and macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVzqVQowfU-g"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIXZtGaAxGT"
   },
   "source": [
    " Use WeightedRandomSampler to balance class sampling in each batch, and customize Trainer to use this sampler during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNwHEoUJXzu"
   },
   "outputs": [],
   "source": [
    "# Extract train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7eIwiU3BKd8"
   },
   "source": [
    " Initialize model **(aubmindlab/araelectra-base-discriminator)** and training configuration with gradient checkpointing and early stopping.\n",
    "\n",
    " Uses a custom SamplerTrainer to address class imbalance, and selects the best model based on macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRxFkq-Mfac7",
    "outputId": "cdda59e6-c391-425c-d4d6-da951853efc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at aubmindlab/araelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-80-3574511343.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.config.hidden_dropout_prob          = 0.3\n",
    "model.config.attention_probs_dropout_prob = 0.3\n",
    "model.config.classifier_dropout           = 0.3\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results_ar\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 6e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    gradient_accumulation_steps   = 2,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 3,\n",
    "    weight_decay              = 0.3,\n",
    "    warmup_ratio              = 0.4,\n",
    "    lr_scheduler_type         = \"cosine\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_ar',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3c1hofoBUCC"
   },
   "source": [
    "Train and fine tuning the model and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "ss4SWIqlU_Iu",
    "outputId": "c5cf3eb0-8981-4a72-cdcd-ed0b54677bf4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='154' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [154/231 01:48 < 00:55, 1.40 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.693499</td>\n",
       "      <td>0.554604</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.502488</td>\n",
       "      <td>0.492683</td>\n",
       "      <td>0.547868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>0.916266</td>\n",
       "      <td>0.513919</td>\n",
       "      <td>0.612717</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.541414</td>\n",
       "      <td>0.512165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNJBQnD-Bd2b"
   },
   "source": [
    "training and evaluation loss logs for each epoch, then evaluate and display final macro F1 scores on the train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "CnmfNKrj39dr",
    "outputId": "8ec261d6-a03f-4251-ebb3-aa89fb65bdbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6807, 'grad_norm': 1.025607943534851, 'learning_rate': 4.9032258064516135e-05, 'epoch': 1.0, 'step': 77}\n",
      "{'eval_loss': 0.6934988498687744, 'eval_accuracy': 0.5546038543897216, 'eval_precision_OBJ': 0.6124031007751938, 'eval_recall_OBJ': 0.5939849624060151, 'eval_f1_OBJ': 0.6030534351145038, 'eval_precision_SUBJ': 0.48325358851674644, 'eval_recall_SUBJ': 0.5024875621890548, 'eval_f1_SUBJ': 0.4926829268292683, 'eval_macro_f1': 0.547868180971886, 'eval_runtime': 0.7163, 'eval_samples_per_second': 651.937, 'eval_steps_per_second': 11.168, 'epoch': 1.0, 'step': 77}\n",
      "{'loss': 0.5738, 'grad_norm': 3.063960075378418, 'learning_rate': 3.610368039157902e-05, 'epoch': 2.0, 'step': 154}\n",
      "{'eval_loss': 0.9162663221359253, 'eval_accuracy': 0.5139186295503212, 'eval_precision_OBJ': 0.6127167630057804, 'eval_recall_OBJ': 0.39849624060150374, 'eval_f1_OBJ': 0.48291571753986334, 'eval_precision_SUBJ': 0.4557823129251701, 'eval_recall_SUBJ': 0.6666666666666666, 'eval_f1_SUBJ': 0.5414141414141415, 'eval_macro_f1': 0.5121649294770024, 'eval_runtime': 0.7115, 'eval_samples_per_second': 656.362, 'eval_steps_per_second': 11.244, 'epoch': 2.0, 'step': 154}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.6315631364449714\n",
      "Val   macro-F1: 0.547868180971886\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EaFmNJCBYaR"
   },
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n50yDmjjHhm5",
    "outputId": "b202e613-5c27-4860-a500-0bbbdd959231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-84-1555866324.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iRdFZIMC_2M"
   },
   "source": [
    "##Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVioY7O0C97k"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.59194**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zvz6tMoXFFDy",
    "outputId": "1acb9e68-bd00-4968-b61f-2629e95932ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.79963, Recall: 0.59835, F1: 0.68450\n",
      "SUBJ – Precision: 0.40650, Recall: 0.64725, F1: 0.49938\n",
      "Macro‐F1: 0.59194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBIy6NsuDeQg"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "aWL_-Eoscm1u",
    "outputId": "8017f154-b80c-414d-bdf3-2e35e0407314"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='224' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.62287, Recall: 0.60235, F1: 0.61244\n",
      "SUBJ – Precision: 0.49852, Recall: 0.52012, F1: 0.50909\n",
      "Macro‐F1: 0.56077\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB9bI1PSDipb"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Obvi8k-4HrZc",
    "outputId": "0e67805a-2f38-43c1-9073-dee8f5c960f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/arabic/arabic_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/arabic/arabic_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE2hO5lAghp3"
   },
   "source": [
    "#Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS5ewMZaDl86"
   },
   "source": [
    "For tokenize data, we use the **mdeberta-v3-base** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "3fa96475628b4b0790d221bbf3e581f4",
      "5b4b50c4a3d04b7c9ebba9938af9ee4e",
      "52f729d45db74900830aaf7856883740",
      "87ad13e5ba3242b7aeeb1295ca1cf4dd",
      "747da2ed82be466cb3433cf440c449a2",
      "6f15385ba10e466d9f2b5d7c4087262a",
      "b9e27ae5245942ed93565e8a474585b5",
      "5b1bf25d309f4896a58b748b64a4f5a3",
      "3b39074f07bb450c83ac30381b2ddb21",
      "496ad210699f49e0b66f524e026839e1",
      "260ea6e87bb2427f958c35a0979f108e",
      "b054bcceabe7447d9271e1b124bd1926",
      "d202cfc4bdc64a22814631802e01063f",
      "3ce0f0554ced4482aa2dcfe70ca9b755",
      "ed3ed7dfd5b842859732d72f2ee0e796",
      "92643c22688045cd8a2de22a4705f641",
      "b9dcd5a1d71c4369be48d6a39e871d80",
      "f5bba29a584d48b087ce4621ff5ab9f0",
      "0ed9dfa96ae24b3d97ab294ab8180ac1",
      "1a248acb188f436fa4aaf4e973334a7d",
      "435b9106f85844c2a52280e994cff4d8",
      "c548dab172794925b36b4ef3df2914ec",
      "5a094e639a894701bede9d9b7699d985",
      "c5efb59d0d84492d9efa4a2f568fb041",
      "cb141fbb590844bb82f7f3482f06106b",
      "6e9f4fb27c604ce1bb178618d5879497",
      "a777c4bb4b844e3a9fe1439f54486f40",
      "55fb45da225a4db19d2daa158bb8b4eb",
      "231252c96a884e76985d90969d78ee6d",
      "403a01caa7024a409fb5939c0502ce05",
      "5e237c1e79434ca3acb883527e021ab9",
      "d3ef90fec0624e08a0c1c8ceca6cf0b1",
      "b40968f2f6ef49bdad9d6b79ae47391f",
      "24ed1bfcd37a45e2a729e5cb0e0f16e1",
      "240dae7a2b08448792c5efd3d05b4c82",
      "7b94c7dec99e4f6ea3b59007cc96f550",
      "f8252f540e424cfe800e2ce87ec856b3",
      "c9c3b404985e4635962a22783aa29a03",
      "d6c19be624d34253be7077f49674b917",
      "6b8b593818884a5e9809c7bd06ad573b",
      "cd4da1430a354ec1b3e84347fe8a8aaf",
      "8521b15c153e484cad14a9721e632923",
      "7341926182644283bbb184e9e4427824",
      "ddb6a59ae9d6488fae1be8bd2f05b272",
      "6f8957c50e91490ab53f0d25019e2875",
      "9883fc5f19bb423cb18e7ed46a86bf2b",
      "9fa58e507eca40a69e43a7996703fcfb",
      "e2e2b9b1765e4cdb8c8eef9dd91c244e",
      "c0f8462d392b473d8d22dffc8f8fd178",
      "846122b8afb241d19dfd14fc217d0e85",
      "b1b59376e15f4f2596374e35554f780f",
      "063a2f581c83465bbfbc10e98851e1cd",
      "bb73ae8083914bc4b2d6121b863cc615",
      "f089ada246d8422d88324eea4a0a069d",
      "91352badf0c74e21875c9ed0aab72280"
     ]
    },
    "id": "VFRuxx1-gklR",
    "outputId": "bb52118d-3967-4b15-d46f-64787638b28c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa96475628b4b0790d221bbf3e581f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b054bcceabe7447d9271e1b124bd1926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a094e639a894701bede9d9b7699d985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ed1bfcd37a45e2a729e5cb0e0f16e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8957c50e91490ab53f0d25019e2875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm09_K7Ugtyf"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_sjUXk4g4wq"
   },
   "outputs": [],
   "source": [
    "# Extract  train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqHtr5LJhDF1",
    "outputId": "b2d28812-2dbc-4004-e887-0a65d92a1793"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-144-2881997415.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results1_ar\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 4e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    gradient_accumulation_steps   = 4,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 3,\n",
    "    weight_decay              = 0.2,\n",
    "    warmup_ratio              = 0.08,\n",
    "    lr_scheduler_type         = \"cosine\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_ar',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "279l_z-fhLyP",
    "outputId": "62db67bc-cfbc-43ce-978e-3a74d30eb2ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/117 09:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.678900</td>\n",
       "      <td>0.693613</td>\n",
       "      <td>0.573876</td>\n",
       "      <td>0.573626</td>\n",
       "      <td>0.981203</td>\n",
       "      <td>0.723994</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.065728</td>\n",
       "      <td>0.394861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>0.693185</td>\n",
       "      <td>0.569593</td>\n",
       "      <td>0.599388</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.661046</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.348259</td>\n",
       "      <td>0.410557</td>\n",
       "      <td>0.535801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.700711</td>\n",
       "      <td>0.563169</td>\n",
       "      <td>0.597484</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.417143</td>\n",
       "      <td>0.533914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic1\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic1\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "zNNjoCq7hY77",
    "outputId": "f3992a5f-2d6c-43c4-80e2-353ef2b6b78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6789, 'grad_norm': 0.6950065493583679, 'learning_rate': 3.361370043098126e-05, 'epoch': 1.0, 'step': 39}\n",
      "{'eval_loss': 0.6936134696006775, 'eval_accuracy': 0.5738758029978587, 'eval_precision_OBJ': 0.5736263736263736, 'eval_recall_OBJ': 0.981203007518797, 'eval_f1_OBJ': 0.723994452149792, 'eval_precision_SUBJ': 0.5833333333333334, 'eval_recall_SUBJ': 0.03482587064676617, 'eval_f1_SUBJ': 0.06572769953051644, 'eval_macro_f1': 0.3948610758401542, 'eval_runtime': 1.0161, 'eval_samples_per_second': 459.579, 'eval_steps_per_second': 7.873, 'epoch': 1.0, 'step': 39}\n",
      "{'loss': 0.6722, 'grad_norm': 0.8246380686759949, 'learning_rate': 1.227856872452637e-05, 'epoch': 2.0, 'step': 78}\n",
      "{'eval_loss': 0.693185031414032, 'eval_accuracy': 0.569593147751606, 'eval_precision_OBJ': 0.599388379204893, 'eval_recall_OBJ': 0.7368421052631579, 'eval_f1_OBJ': 0.6610455311973018, 'eval_precision_SUBJ': 0.5, 'eval_recall_SUBJ': 0.3482587064676617, 'eval_f1_SUBJ': 0.41055718475073316, 'eval_macro_f1': 0.5358013579740175, 'eval_runtime': 1.0179, 'eval_samples_per_second': 458.805, 'eval_steps_per_second': 7.86, 'epoch': 2.0, 'step': 78}\n",
      "{'loss': 0.6576, 'grad_norm': 0.6340006589889526, 'learning_rate': 8.619875460031957e-09, 'epoch': 3.0, 'step': 117}\n",
      "{'eval_loss': 0.7007105350494385, 'eval_accuracy': 0.563169164882227, 'eval_precision_OBJ': 0.5974842767295597, 'eval_recall_OBJ': 0.7142857142857143, 'eval_f1_OBJ': 0.6506849315068494, 'eval_precision_SUBJ': 0.4899328859060403, 'eval_recall_SUBJ': 0.36318407960199006, 'eval_f1_SUBJ': 0.41714285714285715, 'eval_macro_f1': 0.5339138943248533, 'eval_runtime': 1.0265, 'eval_samples_per_second': 454.949, 'eval_steps_per_second': 7.794, 'epoch': 3.0, 'step': 117}\n",
      "{'eval_loss': 0.6578810214996338, 'eval_accuracy': 0.6275551921504497, 'eval_precision_OBJ': 0.6343784994400896, 'eval_recall_OBJ': 0.8145219266714594, 'eval_f1_OBJ': 0.7132514951211835, 'eval_precision_SUBJ': 0.6090909090909091, 'eval_recall_SUBJ': 0.381042654028436, 'eval_f1_SUBJ': 0.46880466472303206, 'eval_macro_f1': 0.5910280799221077, 'eval_runtime': 5.2611, 'eval_samples_per_second': 464.918, 'eval_steps_per_second': 7.413, 'epoch': 3.0, 'step': 117}\n",
      "{'eval_loss': 0.693185031414032, 'eval_accuracy': 0.569593147751606, 'eval_precision_OBJ': 0.599388379204893, 'eval_recall_OBJ': 0.7368421052631579, 'eval_f1_OBJ': 0.6610455311973018, 'eval_precision_SUBJ': 0.5, 'eval_recall_SUBJ': 0.3482587064676617, 'eval_f1_SUBJ': 0.41055718475073316, 'eval_macro_f1': 0.5358013579740175, 'eval_runtime': 0.9975, 'eval_samples_per_second': 468.178, 'eval_steps_per_second': 8.02, 'epoch': 3.0, 'step': 117}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.5910280799221077\n",
      "Val   macro-F1: 0.5358013579740175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSd3iWjXhbtj",
    "outputId": "34fa05d8-6577-47f0-a898-e4526ef510af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-149-763104757.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_arabic1\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSjVR_DdD2GD"
   },
   "source": [
    "##Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfpXHdpKD3n5"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.57380**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "XncAIwT5hhNY",
    "outputId": "ed8628c6-b0e3-472b-8a5a-9235883da5d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.75110, Recall: 0.70564, F1: 0.72766\n",
      "SUBJ – Precision: 0.39377, Recall: 0.44984, F1: 0.41994\n",
      "Macro‐F1: 0.57380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTDClF-ZEAAo"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "ADfVdG3fhkQT",
    "outputId": "b4b5d1f0-7abb-41a5-a409-680f83c8c03d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='224' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.61070, Recall: 0.77882, F1: 0.68459\n",
      "SUBJ – Precision: 0.54369, Recall: 0.34675, F1: 0.42344\n",
      "Macro‐F1: 0.55402\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RalJryUYEJGz"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xZ-HGpMuhndW",
    "outputId": "0e411f9d-c66f-4442-d3cf-4c33c6211f89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/arabic/arabic_predictions1.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/arabic/arabic_predictions1.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
