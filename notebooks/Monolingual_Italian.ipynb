{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbVu6-tt6oo_"
   },
   "source": [
    "##Monolingual_Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1s_3uGOyWHw",
    "outputId": "201c6485-a1ab-4792-d1d8-c52b436eaeb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cVXzdYXLdvF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1dT7TUE8gJx"
   },
   "source": [
    "##Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP5PEFU4yjto"
   },
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/data/italian'\n",
    "train_path = f'{base_dir}/train_it.tsv'\n",
    "dev_path   = f'{base_dir}/dev_it.tsv'\n",
    "dev_test_path = f'{base_dir}/dev_test_it.tsv'\n",
    "test_path = f'{base_dir}/test_it_labeled.tsv'\n",
    "test_unlabeled_path = f'{base_dir}/test_it_unlabeled.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvRILJGrNOyQ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df   = pd.read_csv(dev_path, sep='\\t')\n",
    "dev_test_df = pd.read_csv(dev_test_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "test_unlabeled_df = pd.read_csv(test_unlabeled_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLkcV1mW8heZ"
   },
   "source": [
    "##Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Wsl9Jgtdlfw",
    "outputId": "7b11bd0a-ad68-4113-f4d3-8314924c967d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped classes: {0: 'OBJ', 1: 'SUBJ'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['label_id']    = le.fit_transform(train_df['label'])\n",
    "dev_df['label_id']      = le.transform(dev_df['label'])\n",
    "dev_test_df['label_id'] = le.transform(dev_test_df['label'])\n",
    "test_df['label_id']     = le.transform(test_df['label'])\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.rename(columns={'label_id':'labels'}, inplace=True)\n",
    "\n",
    "print(\"Mapped classes:\", dict(enumerate(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl61hFt2dpZY"
   },
   "outputs": [],
   "source": [
    "train_ds    = Dataset.from_pandas(train_df[['sentence','labels']])\n",
    "dev_ds      = Dataset.from_pandas(dev_df[['sentence','labels']])\n",
    "dev_test_ds = Dataset.from_pandas(dev_test_df[['sentence','labels']])\n",
    "test_ds = Dataset.from_pandas(test_df[['sentence','labels']])\n",
    "test_unlabeled_ds = Dataset.from_pandas(test_unlabeled_df[['sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "252vkRToOaYH",
    "outputId": "7162da06-85f4-4ae1-bf0a-cd87bfb3e00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts → OBJ: 1231, SUBJ: 382\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(train_ds['labels'])\n",
    "n_obj, n_subj = counts[0], counts[1]\n",
    "print(f\"Original counts → OBJ: {n_obj}, SUBJ: {n_subj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaRUUu3k8oUO"
   },
   "source": [
    "#First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFuX_OKT8tHO"
   },
   "source": [
    "For tokenize data, we use the **musixmatch/umberto-commoncrawl-cased-v1** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397,
     "referenced_widgets": [
      "6185987a09e94a48be7355e9fae80db1",
      "8c034f532ff04c75978c40b8b981c8c6",
      "5abcc328297c4ccda3e6df645d47bc1b",
      "efd426b5facc48bfa731a79905cc8899",
      "6bc9259c724c48f4837d577e1f1dda6f",
      "ebbe282d539646d394e2e3e3ac4a6415",
      "48f84cab38a44c1482b31fb7745498d6",
      "51dc5e82e9254107a7cf09a235f8cf19",
      "4ab99157acda48d4bea8eb3bc445ef63",
      "d6ab8eb682f147e99ad7e858d7a041ad",
      "204d025b4c424b5caff709446c70e45a",
      "a415dbcdf11642c6a969564ea0046b9a",
      "233099572f51404baca22d2476e58ad5",
      "364175ac5d694141bb5686bac84a1a20",
      "9c45ce43f0064eabbf0e4d6cc712e7a3",
      "4953de4f62e74565bcb38aa5774b2bd4",
      "0724ce1fe6e3488ab30136fbc8bf9593",
      "9f46a76e3e4e4541b35ca7bd253d4f5b",
      "0f7d70cf5f614718a690e5733cbcd6eb",
      "60b51b9533ba4e86b0c7fbd9d9357d28",
      "c29e9775fa2848ada3ffb8f99549bfe3",
      "ab9721f8200e4badb79b40093c4f4d9e",
      "11d1dddfecf847afbb66f16c9d262cf7",
      "f68acb1ab07f478fa15cace39ece9403",
      "0b8f152909b64691b5744cdda97efde2",
      "fbd89228419d477386bfce2bdc78a9b8",
      "787db18b8bef4eb28db3b8b1cb639fba",
      "d59a1084c0e64218bf2e9308a8b45704",
      "833c5f64ecde499e9cd0721173331397",
      "21aaa26e096949f3adc3c4c119975cb2",
      "8bd6216c049f4fcba685ca8af405ac01",
      "a751f38347334a2192c554d4628acb50",
      "d2474826197a46f5a6701e75d1ac158e",
      "daf5d9f0f96744b3909b6257403037ae",
      "6f1c9cbfafa54ceda72a1bef8a48f5e6",
      "69603dc2c7264353a36ed16b0fc75fb3",
      "5e886b116e7148d4a44b6ca3d034ab46",
      "5ce1df614de448d9b349f3ba180d1889",
      "4cde3758c3b7452487751dac77f7a6f6",
      "603be60b42c44b5ab66bed1519d5a7d0",
      "f1644945c08941ed9e269a0d05e211a0",
      "5937b047567440328f61e9dfd8250b86",
      "05357e741b9b419d91fdf414428dfe93",
      "c3e8ebf591cf4f5c87bd3ca2e2fa4b96",
      "4499a47aca274aad8ab87c75b7161337",
      "4a6c504e1dd54963acc06df93bdec2f8",
      "287bc6dadc2c4680955f1013f93a684b",
      "bf4e2bf149024e0baac79aba4d2b9f6e",
      "20b98c8cb06c4424881526b881966082",
      "366a3c1672d24b8d8e658877738c49c6",
      "15c246cb2b504f399f783b9fd19817dc",
      "3afd9944d0df48e7a07b1e19d71b46e2",
      "6dcb1a030eef4a2b90048a012d33a636",
      "a3dcc2353d8d42fca1f5180a4bf10e50",
      "1eb54699177343f286fb3677b7fd22f9",
      "ee5b38088b9a4eb68ce84f4ebce8c0d2",
      "023d5dd52e8a471aae2d89d64720b5c6",
      "90e0fb0d36d14330bd934bc962a43c50",
      "ef934126d1234657abba728d2f84ac89",
      "949a44394717482eb38b33f55351cc10",
      "663a92adc11f4849bab924be394b1db4",
      "3d61ad576a524cb8a4a331c5455bb210",
      "404f0ae8c97a41aa823408e58c69e652",
      "e6953ca492894a93830bf014bd2c9145",
      "9feb5f38a0f54a548410b5bbf10f1b6e",
      "53f84ec1e25b42c2b7d18b5cebc1f174",
      "bfb6364d420d4695ba3ee7ee60c8d106",
      "2cccdefeed1f44fa91811125ab74f046",
      "8a8c17c7444d477499a9726e9f31d181",
      "3f7f6f96c88a432a914ed3516c89c8e9",
      "55008dcb20c14ec1a40a5c0d7c90fec7",
      "aca3a570a6fd4a09a1eac2554b454b17",
      "c036701cfbdb4385a933d8de3ab13b42",
      "76f229c6222b40a1be715313240ebc92",
      "b881841d28064225962923935343aa37",
      "bd008b0d08524ec0b484bf03284de701",
      "1a8e67722c024650a4a6ad8056f141a9",
      "7fafaa7a9ca84e6bb94d1ec0f6be04c7",
      "c31b2b1b06054cdca98c41b61cdad5d3",
      "c3e9953245424498852714955bd37254",
      "42076defb419400bbf53e8947db1d772",
      "b8987e16e0f14cdc871f1e6963a78a34",
      "fb9a17aeb39141a4bdded28c9c160416",
      "ca7e59f55422472e9d2bc96e14e1174c",
      "9f141e2d6c984643b335fcbfbf256e28",
      "3fbd5834af3d475f91be0bad18bf100d",
      "f914f381e99c4d7a8326b933cd3ea8a8",
      "f45bbb66d0f94e9ab46d1b606d1f17af"
     ]
    },
    "id": "haRpwKSrdvcv",
    "outputId": "848fc35b-87a5-4b59-c115-2fedb8105893"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6185987a09e94a48be7355e9fae80db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a415dbcdf11642c6a969564ea0046b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/794k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d1dddfecf847afbb66f16c9d262cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf5d9f0f96744b3909b6257403037ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1613 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4499a47aca274aad8ab87c75b7161337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5b38088b9a4eb68ce84f4ebce8c0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6364d420d4695ba3ee7ee60c8d106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fafaa7a9ca84e6bb94d1ec0f6be04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"musixmatch/umberto-commoncrawl-cased-v1\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeKDsc5-873w"
   },
   "source": [
    " Define a data collator for dynamic padding and a metrics function to compute per-class precision, recall, F1, and macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVzqVQowfU-g"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUaxs9mO8_w9"
   },
   "source": [
    " Use WeightedRandomSampler to balance class sampling in each batch, and customize Trainer to use this sampler during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNwHEoUJXzu"
   },
   "outputs": [],
   "source": [
    "# Extract train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3Msa9iS9V7X"
   },
   "source": [
    " Initialize model **(musixmatch/umberto-commoncrawl-cased-v1)** and training configuration with gradient checkpointing and early stopping.\n",
    "\n",
    " Uses a custom SamplerTrainer to address class imbalance, and selects the best model based on macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRxFkq-Mfac7",
    "outputId": "0230468f-9549-47d6-ebae-abe49bcb70f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at musixmatch/umberto-commoncrawl-cased-v1 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-35-1624914490.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results_it\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 5e-5,\n",
    "    per_device_train_batch_size = 32,\n",
    "    gradient_accumulation_steps   = 2,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 6,\n",
    "    weight_decay              = 0.1,\n",
    "    warmup_ratio              = 0.15,\n",
    "    lr_scheduler_type         = \"linear\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_it',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c676JWSx9vXf"
   },
   "source": [
    "Train and fine tuning the model and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "ss4SWIqlU_Iu",
    "outputId": "47227f5e-6980-4d59-c1aa-3f577f99542f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/156 02:19 < 00:28, 0.92 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.661962</td>\n",
       "      <td>0.590705</td>\n",
       "      <td>0.883392</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.646831</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>0.710614</td>\n",
       "      <td>0.595202</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.477551</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.389021</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>0.546980</td>\n",
       "      <td>0.590563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.615872</td>\n",
       "      <td>0.754123</td>\n",
       "      <td>0.897561</td>\n",
       "      <td>0.751020</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.525292</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.622120</td>\n",
       "      <td>0.719949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.544527</td>\n",
       "      <td>0.778111</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.845188</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.649718</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.726827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.611802</td>\n",
       "      <td>0.766117</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.836820</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.712061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n6WxBK394DD"
   },
   "source": [
    "training and evaluation loss logs for each epoch, then evaluate and display final macro F1 scores on the train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "CnmfNKrj39dr",
    "outputId": "992ff32d-bd9d-4c2d-9521-a292cae68f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6674, 'grad_norm': 1.0850462913513184, 'learning_rate': 4.962121212121213e-05, 'epoch': 1.0, 'step': 26}\n",
      "{'eval_loss': 0.6619623899459839, 'eval_accuracy': 0.5907046476761619, 'eval_precision_OBJ': 0.8833922261484098, 'eval_recall_OBJ': 0.5102040816326531, 'eval_f1_OBJ': 0.6468305304010349, 'eval_precision_SUBJ': 0.375, 'eval_recall_SUBJ': 0.8135593220338984, 'eval_f1_SUBJ': 0.5133689839572193, 'eval_macro_f1': 0.5800997571791271, 'eval_runtime': 0.8418, 'eval_samples_per_second': 792.378, 'eval_steps_per_second': 13.068, 'epoch': 1.0, 'step': 26}\n",
      "{'loss': 0.5421, 'grad_norm': 2.3427186012268066, 'learning_rate': 3.9772727272727275e-05, 'epoch': 2.0, 'step': 52}\n",
      "{'eval_loss': 0.710614025592804, 'eval_accuracy': 0.5952023988005997, 'eval_precision_OBJ': 0.9435483870967742, 'eval_recall_OBJ': 0.4775510204081633, 'eval_f1_OBJ': 0.6341463414634146, 'eval_precision_SUBJ': 0.38902147971360385, 'eval_recall_SUBJ': 0.9209039548022598, 'eval_f1_SUBJ': 0.5469798657718121, 'eval_macro_f1': 0.5905631036176133, 'eval_runtime': 0.9013, 'eval_samples_per_second': 740.005, 'eval_steps_per_second': 12.204, 'epoch': 2.0, 'step': 52}\n",
      "{'loss': 0.4143, 'grad_norm': 3.4925239086151123, 'learning_rate': 2.9924242424242427e-05, 'epoch': 3.0, 'step': 78}\n",
      "{'eval_loss': 0.6158724427223206, 'eval_accuracy': 0.7541229385307346, 'eval_precision_OBJ': 0.8975609756097561, 'eval_recall_OBJ': 0.7510204081632653, 'eval_f1_OBJ': 0.8177777777777778, 'eval_precision_SUBJ': 0.5252918287937743, 'eval_recall_SUBJ': 0.7627118644067796, 'eval_f1_SUBJ': 0.6221198156682027, 'eval_macro_f1': 0.7199487967229903, 'eval_runtime': 0.8467, 'eval_samples_per_second': 787.798, 'eval_steps_per_second': 12.992, 'epoch': 3.0, 'step': 78}\n",
      "{'loss': 0.3622, 'grad_norm': 1.2040778398513794, 'learning_rate': 2.0075757575757575e-05, 'epoch': 4.0, 'step': 104}\n",
      "{'eval_loss': 0.5445266962051392, 'eval_accuracy': 0.7781109445277361, 'eval_precision_OBJ': 0.8669527896995708, 'eval_recall_OBJ': 0.8244897959183674, 'eval_f1_OBJ': 0.8451882845188284, 'eval_precision_SUBJ': 0.572139303482587, 'eval_recall_SUBJ': 0.6497175141242938, 'eval_f1_SUBJ': 0.6084656084656085, 'eval_macro_f1': 0.7268269464922185, 'eval_runtime': 0.884, 'eval_samples_per_second': 754.536, 'eval_steps_per_second': 12.444, 'epoch': 4.0, 'step': 104}\n",
      "{'loss': 0.2935, 'grad_norm': 0.05560717731714249, 'learning_rate': 1.0606060606060607e-05, 'epoch': 5.0, 'step': 130}\n",
      "{'eval_loss': 0.6118021607398987, 'eval_accuracy': 0.7661169415292354, 'eval_precision_OBJ': 0.8583690987124464, 'eval_recall_OBJ': 0.8163265306122449, 'eval_f1_OBJ': 0.8368200836820083, 'eval_precision_SUBJ': 0.5522388059701493, 'eval_recall_SUBJ': 0.6271186440677966, 'eval_f1_SUBJ': 0.5873015873015873, 'eval_macro_f1': 0.7120608354917979, 'eval_runtime': 0.8269, 'eval_samples_per_second': 806.626, 'eval_steps_per_second': 13.303, 'epoch': 5.0, 'step': 130}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.9228856134502668\n",
      "Val   macro-F1: 0.7268269464922185\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n50yDmjjHhm5",
    "outputId": "b283950b-f267-4c1b-fff9-ec9111b913f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-40-3014590974.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMEMmkFC-PgQ"
   },
   "source": [
    "##Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu5WzeR4-VBQ"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.73341**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zvz6tMoXFFDy",
    "outputId": "aa56e5ce-5ee4-4005-dc3c-fddd8b2f55ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.80000, Recall: 0.83333, F1: 0.81633\n",
      "SUBJ – Precision: 0.67677, Recall: 0.62617, F1: 0.65049\n",
      "Macro‐F1: 0.73341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HewL1cG0-NJ7"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "aWL_-Eoscm1u",
    "outputId": "de32f61d-1c53-43da-966a-bbb85cdf6744"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.87179, Recall: 0.91617, F1: 0.89343\n",
      "SUBJ – Precision: 0.74775, Recall: 0.64844, F1: 0.69456\n",
      "Macro‐F1: 0.79400\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fyebwbl-JR6"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Obvi8k-4HrZc",
    "outputId": "00e028d5-155f-4963-f995-f3770639335f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/italian/italian_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/italian/italian_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE2hO5lAghp3"
   },
   "source": [
    "#Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mlytH_q-zDQ"
   },
   "source": [
    "For tokenize data, we use the **mdeberta-v3-base** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "1558dddf919b4156aff362722680ef6e",
      "a11dc66b880f479b9de6635ae8b0722d",
      "c2ba0939b0b7487fb8579f68a689d6bc",
      "f3fbd86d9be540b3999f33fae4e6befb",
      "16d417667d22455d9d8e76778fb78a3a",
      "d41958fb25844bb887baccd4b719ce0c",
      "e516e926b57746b5a2f25355babaea0a",
      "78aff0b14bf4429daa4f7b436f5e2d89",
      "b40e988b081f4f888a8ed67d2c2b2d65",
      "ff7757b1e088474d86e8ffaf3ddd6c96",
      "38836c712257431bb853bbdc3aba8bf6",
      "d204b6e387034ddeb39abb8bf1ee9155",
      "3e9588d6e6034c9d80533aeabc1802cb",
      "2e2d977e68494fe5a6925f4c884ab4ab",
      "5de9dd4179704aacbc91c3baa6a04613",
      "a1903ca43b0749ef9a09ed3f8f2b23f7",
      "72870e4add5f49e591f3cb5526538eef",
      "9b95e645ecae475b9c56a8e957531f2a",
      "b242d597106e44a99cd2037f63178dc8",
      "dd61dde1ca9947b089634fa254d39c6b",
      "d07036f4aded4afeb477f8d977cfc4c7",
      "db375f8764a94734b03318d3dd24950c",
      "33ecce96315349409898762d4a912983",
      "b36d94cabc4c4c44ace278d06d8593a3",
      "b307914e22a54637bec78dd7575e96f9",
      "73559138c75e4b54a3373a5bb6023bdc",
      "3d70b9fd6b9a41f3a4e9e93794bf9627",
      "7b50dbc0c56d4a5397decbc948232dd6",
      "3cc67e02d8684fddbb5db60e40fc3d72",
      "02fe776b407a476283c74a1811e7de74",
      "b7f95dc7cdde423880b87f3491dc0924",
      "79b595eafb23440eb6a071bf2ddf97c0",
      "d33d8a97a8fd4d4490fabb97f11b9935",
      "b1b03854cf034534853525e2a107679d",
      "7dd7ae0589994e008856a91291057d38",
      "5ad5989ea5a04d6bb40bc887326ece6d",
      "ebce2a10f0ac488db001896e346770a3",
      "18633f2055bc44ac844d4fc15e612428",
      "36737d30dd684b5ca03af463529f74ba",
      "3b20e3301596445cbc926124c8c1c38a",
      "ec0d0a0c8fad47fb9b9556816cb02b52",
      "36b151a59d3a4cb48b1970de6e13ec2c",
      "06ed1d87c69d4865add34a4c0d987cc1",
      "cd72a5fa14804fc79528c5559d25586d",
      "d77803a3c9a04c75a1f68a29a62e8efd",
      "6da20b6f7fb040bbbb75f1d93f4fa74c",
      "c9294fd0203d452d8abc029c3b79e2b6",
      "07f9d2d5e15f4774b0c751024d1b4256",
      "0b0fdd31a9b64ed9ba59af2db1665773",
      "b09d6ca28c0f4d60b1d30f56fb7d8492",
      "7fb601ad535c4941bd5cc433b81a5342",
      "0f5ab1b82b57477ebdef58fc9e5e318d",
      "f7a8954ab83349a89d235ab790daa845",
      "a0613ae3458848ca89f4dc2cc3923836",
      "c4c34e12743f40b49ed5324d0520c271",
      "8be75ae55f404392a835bc61e68fb4fe",
      "807d880df72f490ebf65233afe47909d",
      "d2f14bb0028643f0ad3aafaf7f57c7a3",
      "8beb962bbd1a4eb8b8108e816acb25a4",
      "98106e02d41b4dacb9f7e5fd891984b3",
      "f9fd607f3a3a452b8bbff8936396d361",
      "40f8492e892449e4a07aecc4501ef1d1",
      "e4e88696a35548b7826ab59f0ece262d",
      "bb19bd5dd7724bf78fde207e3457fe7b",
      "e0908a258b894abd830245636a27d318",
      "6fc8e46bcf6f4f30b109b604c487eecc",
      "3ca07c2ffa864c20a5497e3e1737c7a7",
      "24d5fcf12cdf48fda2f68f3b27339d67",
      "a53d7b575c8c4cd49d91a8d18bce408d",
      "1f4f0b5a9a754b71bda2a6105cade848",
      "9cf26013743b4c318419248a33686b21",
      "6c9e51b014e94461ac69e6124cd27e85",
      "cef854bc6d364716ac46aed40ad7ed2f",
      "f16c3f2044344beea4df48c0cda95353",
      "8b5b7f920c6945eb80ef8833efe87996",
      "6aa0bab49f0449ba8812fcf4006141de",
      "21529fa6cd204f17b7f2822783eede3d",
      "14e801291aea4cbfbef59e021d92ff66",
      "c846291f9c47428f973050693bd161f7",
      "5d18957474ea400e98e97d99f3b6f575",
      "9184ca6389a84a8e8d77c472610715dc",
      "8fa1dc473dba4513b418a6fb7cbf42b5",
      "0e1630413b2041c5bd025497c434547d",
      "35efd847c79c4a9586eba4bb4b4edd36",
      "4f10ce0197d74078a09f6fafa2d9bf8a",
      "67258924a5c746aa96872e59bb96d62f",
      "985a8dc42c954f13bdb7df3bebefd06a",
      "893007e4a7db460c87db357ecc703be6"
     ]
    },
    "id": "VFRuxx1-gklR",
    "outputId": "727050f3-caf7-4768-d74e-6bfa2c218fa7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1558dddf919b4156aff362722680ef6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d204b6e387034ddeb39abb8bf1ee9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ecce96315349409898762d4a912983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b03854cf034534853525e2a107679d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1613 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77803a3c9a04c75a1f68a29a62e8efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be75ae55f404392a835bc61e68fb4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca07c2ffa864c20a5497e3e1737c7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e801291aea4cbfbef59e021d92ff66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm09_K7Ugtyf"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_sjUXk4g4wq"
   },
   "outputs": [],
   "source": [
    "#  Extract train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqHtr5LJhDF1",
    "outputId": "57521f7f-fd7c-4a61-9adc-b43374e97acd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-60-2402227654.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results1_it\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 5e-5,\n",
    "    per_device_train_batch_size = 32,\n",
    "    gradient_accumulation_steps   = 2,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs          = 6,\n",
    "    weight_decay              = 0.1,\n",
    "    warmup_ratio              = 0.15,\n",
    "    lr_scheduler_type         = \"linear\",\n",
    "    label_smoothing_factor    = 0.1,\n",
    "    max_grad_norm             = 1.0,\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_it',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "279l_z-fhLyP",
    "outputId": "72433d62-861e-41c9-f717-13ea05d73c9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='104' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [104/156 06:53 < 03:30, 0.25 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.688871</td>\n",
       "      <td>0.587706</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.465306</td>\n",
       "      <td>0.623803</td>\n",
       "      <td>0.384977</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.543947</td>\n",
       "      <td>0.583875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.640166</td>\n",
       "      <td>0.710645</td>\n",
       "      <td>0.943284</td>\n",
       "      <td>0.644898</td>\n",
       "      <td>0.766061</td>\n",
       "      <td>0.475904</td>\n",
       "      <td>0.892655</td>\n",
       "      <td>0.620825</td>\n",
       "      <td>0.693443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.526150</td>\n",
       "      <td>0.814093</td>\n",
       "      <td>0.899563</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.626794</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>0.773977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.540069</td>\n",
       "      <td>0.796102</td>\n",
       "      <td>0.895089</td>\n",
       "      <td>0.818367</td>\n",
       "      <td>0.855011</td>\n",
       "      <td>0.593607</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.755788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian1\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian1\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "zNNjoCq7hY77",
    "outputId": "9340841f-2e14-488e-9489-61bf5f91bead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6694, 'grad_norm': 5.452830791473389, 'learning_rate': 4.962121212121213e-05, 'epoch': 1.0, 'step': 26}\n",
      "{'eval_loss': 0.688871443271637, 'eval_accuracy': 0.5877061469265368, 'eval_precision_OBJ': 0.946058091286307, 'eval_recall_OBJ': 0.46530612244897956, 'eval_f1_OBJ': 0.6238030095759234, 'eval_precision_SUBJ': 0.38497652582159625, 'eval_recall_SUBJ': 0.9265536723163842, 'eval_f1_SUBJ': 0.5439469320066335, 'eval_macro_f1': 0.5838749707912785, 'eval_runtime': 1.4405, 'eval_samples_per_second': 463.018, 'eval_steps_per_second': 7.636, 'epoch': 1.0, 'step': 26}\n",
      "{'loss': 0.5218, 'grad_norm': 5.016152381896973, 'learning_rate': 3.9772727272727275e-05, 'epoch': 2.0, 'step': 52}\n",
      "{'eval_loss': 0.6401657462120056, 'eval_accuracy': 0.7106446776611695, 'eval_precision_OBJ': 0.9432835820895522, 'eval_recall_OBJ': 0.6448979591836734, 'eval_f1_OBJ': 0.7660606060606061, 'eval_precision_SUBJ': 0.4759036144578313, 'eval_recall_SUBJ': 0.8926553672316384, 'eval_f1_SUBJ': 0.6208251473477406, 'eval_macro_f1': 0.6934428767041734, 'eval_runtime': 1.4608, 'eval_samples_per_second': 456.609, 'eval_steps_per_second': 7.53, 'epoch': 2.0, 'step': 52}\n",
      "{'loss': 0.3803, 'grad_norm': 3.696323871612549, 'learning_rate': 2.9924242424242427e-05, 'epoch': 3.0, 'step': 78}\n",
      "{'eval_loss': 0.5261504054069519, 'eval_accuracy': 0.8140929535232384, 'eval_precision_OBJ': 0.8995633187772926, 'eval_recall_OBJ': 0.8408163265306122, 'eval_f1_OBJ': 0.869198312236287, 'eval_precision_SUBJ': 0.6267942583732058, 'eval_recall_SUBJ': 0.7401129943502824, 'eval_f1_SUBJ': 0.6787564766839378, 'eval_macro_f1': 0.7739773944601124, 'eval_runtime': 1.5251, 'eval_samples_per_second': 437.343, 'eval_steps_per_second': 7.213, 'epoch': 3.0, 'step': 78}\n",
      "{'loss': 0.3206, 'grad_norm': 2.3947510719299316, 'learning_rate': 2.0075757575757575e-05, 'epoch': 4.0, 'step': 104}\n",
      "{'eval_loss': 0.5400694608688354, 'eval_accuracy': 0.7961019490254873, 'eval_precision_OBJ': 0.8950892857142857, 'eval_recall_OBJ': 0.8183673469387756, 'eval_f1_OBJ': 0.8550106609808102, 'eval_precision_SUBJ': 0.593607305936073, 'eval_recall_SUBJ': 0.7344632768361582, 'eval_f1_SUBJ': 0.6565656565656566, 'eval_macro_f1': 0.7557881587732334, 'eval_runtime': 1.471, 'eval_samples_per_second': 453.437, 'eval_steps_per_second': 7.478, 'epoch': 4.0, 'step': 104}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.9177898760569907\n",
      "Val   macro-F1: 0.7739773944601124\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSd3iWjXhbtj",
    "outputId": "744f6fee-211d-4ed4-8881-4c2d4170bb07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-64-2104084622.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_italian1\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TagnyA6O_RQb"
   },
   "source": [
    "##Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk6OZk5v_Qxl"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.77075**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "XncAIwT5hhNY",
    "outputId": "ad5aa1f6-8c0b-424e-cb90-c5f8d46a579a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.84783, Recall: 0.81250, F1: 0.82979\n",
      "SUBJ – Precision: 0.68696, Recall: 0.73832, F1: 0.71171\n",
      "Macro‐F1: 0.77075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2r3ATMRT_hMu"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "ADfVdG3fhkQT",
    "outputId": "d9cc09c9-edca-4415-efea-863752a93405"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.88663, Recall: 0.91317, F1: 0.89971\n",
      "SUBJ – Precision: 0.75424, Recall: 0.69531, F1: 0.72358\n",
      "Macro‐F1: 0.81164\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbgbPBvT_qQu"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xZ-HGpMuhndW",
    "outputId": "104bf47d-dafa-4b09-e7ab-d5c3041b2395"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/italian/italian_predictions1.tsv\n"
     ]
    }
   ],
   "source": [
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/italian/italian_predictions1.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
