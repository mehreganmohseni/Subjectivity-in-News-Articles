{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbVu6-tt6oo_"
   },
   "source": [
    "#Monolingual_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1s_3uGOyWHw",
    "outputId": "021247fe-09f4-4d01-d50d-46c3c30b58ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cVXzdYXLdvF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from transformers import DataCollatorWithPadding, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBirUTt1qMF"
   },
   "source": [
    "##Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP5PEFU4yjto"
   },
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/data/english'\n",
    "train_path = f'{base_dir}/train_en.tsv'\n",
    "dev_path   = f'{base_dir}/dev_en.tsv'\n",
    "dev_test_path = f'{base_dir}/dev_test_en.tsv'\n",
    "test_path = f'{base_dir}/test_en_labeled.tsv'\n",
    "test_unlabeled_path = f'{base_dir}/test_en_unlabeled.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvRILJGrNOyQ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "dev_df   = pd.read_csv(dev_path, sep='\\t')\n",
    "dev_test_df = pd.read_csv(dev_test_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "test_unlabeled_df = pd.read_csv(test_unlabeled_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9-g2Y1q2fBf"
   },
   "source": [
    "##Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Wsl9Jgtdlfw",
    "outputId": "6d9d22fa-9ca5-41e6-9308-349781f9df0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped classes: {0: 'OBJ', 1: 'SUBJ'}\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['label_id']    = le.fit_transform(train_df['label'])\n",
    "dev_df['label_id']      = le.transform(dev_df['label'])\n",
    "dev_test_df['label_id'] = le.transform(dev_test_df['label'])\n",
    "test_df['label_id']     = le.transform(test_df['label'])\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "for df in (train_df, dev_df, dev_test_df, test_df):\n",
    "    df.rename(columns={'label_id':'labels'}, inplace=True)\n",
    "\n",
    "print(\"Mapped classes:\", dict(enumerate(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl61hFt2dpZY"
   },
   "outputs": [],
   "source": [
    "train_ds    = Dataset.from_pandas(train_df[['sentence','labels']])\n",
    "dev_ds      = Dataset.from_pandas(dev_df[['sentence','labels']])\n",
    "dev_test_ds = Dataset.from_pandas(dev_test_df[['sentence','labels']])\n",
    "test_ds = Dataset.from_pandas(test_df[['sentence','labels']])\n",
    "test_unlabeled_ds = Dataset.from_pandas(test_unlabeled_df[['sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "252vkRToOaYH",
    "outputId": "3155db68-ff0a-4c5b-98fb-4c16e17e386c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts → OBJ: 532, SUBJ: 298\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(train_ds['labels'])\n",
    "n_obj, n_subj = counts[0], counts[1]\n",
    "print(f\"Original counts → OBJ: {n_obj}, SUBJ: {n_subj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiTD5wn960uQ"
   },
   "source": [
    "#Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_7WpW7I2u7T"
   },
   "source": [
    "For tokenize data, we use the **mDeBERTaV3_base** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "357584207a4e4fd794b90c36dc9a45c1",
      "ff7905680d404c08b28d82f6139d2f65",
      "cefa70701afd4dc099c107bf388631d3",
      "af2167ca585a49c6ab6b655fd08d42bb",
      "f2fb89546369448386e39b7e19d2798a",
      "a7100575c23144afbed0f6b09c5e96a1",
      "9605b73a3c70406388c243b4303e4b49",
      "b9c1f774e4314eae8401ed05860981cd",
      "1b13f3f91ca14d919888826a1cc1a213",
      "f131ae09861f4db1bee94a2b749ca5ba",
      "f93bfedb5f9844a385da8bb7193c2d2b",
      "c1a653eb49b84106ac8f73572ba71f98",
      "7f23be75047d4cd39d03700db9fd497e",
      "d81465cfdf594206b8a40eafa0fd949d",
      "9c0d8ef055854b5cb569832e50d723c3",
      "b8c9ec1605de49cb8ad4372f09f82c32",
      "72565f16aed8421a90aa3239487ba7e3",
      "1535a909ea224845a6249aef9f600377",
      "d89bd98c844a4121a053999d5c943957",
      "c9142b08e04e43278210f911ebc556f3",
      "d115601a32034b6a923d93632cef8f74",
      "1df630f6e9154eee9959ff6d40cff0d4",
      "0ee628b8607049dd9cc57bf0be164e33",
      "a398b34a4c6d4294aa7060c4535e9829",
      "4ceec91f60124443a71a4841a624b1a1",
      "a2e0523405904cf18bcccba194fb6106",
      "0868ae087e2f4fbca6c712f56c293413",
      "fdc995ea7d274e48994de93d14728166",
      "fffd25a624de4529831df50c85292a51",
      "94db30a1ee8a46eaa4206ec71819c947",
      "d0b3826eac5e44a6af573ae412c5075d",
      "5ce17ea7c3a64e9db070b08044fcfaa3",
      "8376dd8f1c9c4e6d93a97a265acc3917",
      "ebe0882f750e4cb6b1bc0532c742eae2",
      "349163e92f2445e7aae7770528d04dc6",
      "ccd1dfc56f484c84865a02df851949dc",
      "0a0f44708bfa41f48a0e96629e9b55a4",
      "fe20a940a3de4bbea8bae63a67050b38",
      "5b08bb2b0cd3401aa163ccb6644ce192",
      "20ce92d6ce2444d09d705637afaeede5",
      "8f9235bd440d4070ab53d7431aeceb86",
      "1d8fb13a72fe4cbebf6bece734df4513",
      "628843e8426a4a9086a6314a2790229f",
      "896bdd15e82e44e39d77fa69b78b18e3",
      "46f6cfe11cc5443bbf95d7a3272450ec",
      "9af8375306774db794416c1bc81cd413",
      "9faa638d88e24834846e312642fda457",
      "4c03c819f5d34ec58570b46cd41df556",
      "995cd848eb6845df9265afa3b5dac9d0",
      "dad64775d05e4518bec4cce1bef0e493",
      "78ec500a8eae48e39221616e9a9fbf1c",
      "e28e04f0b3314f638476536d85a8ebbe",
      "ff4ab764304c4b06adc58126501d51a8",
      "0a009d5ddd99456f9f32bb07e211ebcf",
      "425454d4e4c84613af1accf5e1ee001a"
     ]
    },
    "id": "haRpwKSrdvcv",
    "outputId": "58b3306f-081a-4215-982b-02503e9f4ee0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357584207a4e4fd794b90c36dc9a45c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a653eb49b84106ac8f73572ba71f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee628b8607049dd9cc57bf0be164e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe0882f750e4cb6b1bc0532c742eae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f6cfe11cc5443bbf95d7a3272450ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "max_len = 100\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['sentence'],\n",
    "                     padding='max_length',\n",
    "                     truncation=True,\n",
    "                     max_length=max_len)\n",
    "\n",
    "train_ds    = train_ds.map(tokenize, batched=True)\n",
    "dev_ds      = dev_ds.map(tokenize, batched=True)\n",
    "dev_test_ds = dev_test_ds.map(tokenize, batched=True)\n",
    "test_ds     = test_ds.map(tokenize, batched=True)\n",
    "test_unlabeled_ds = test_unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = ['input_ids','attention_mask','labels']\n",
    "train_ds    = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols])\n",
    "dev_ds      = dev_ds.remove_columns([c for c in dev_ds.column_names if c not in cols])\n",
    "dev_test_ds = dev_test_ds.remove_columns([c for c in dev_test_ds.column_names if c not in cols])\n",
    "test_ds     = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols])\n",
    "test_unlabeled_ds = test_unlabeled_ds.remove_columns(\n",
    "    [c for c in test_unlabeled_ds.column_names if c not in ['input_ids','attention_mask']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnvy1uVxDsCR"
   },
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gn30EJKCmPE"
   },
   "source": [
    " Define a data collator for dynamic padding and a metrics function to compute per-class precision, recall, F1, and macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVzqVQowfU-g"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, labels=[0,1], zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision_OBJ': precision[0],\n",
    "        'recall_OBJ':    recall[0],\n",
    "        'f1_OBJ':        f1[0],\n",
    "        'precision_SUBJ':precision[1],\n",
    "        'recall_SUBJ':   recall[1],\n",
    "        'f1_SUBJ':       f1[1],\n",
    "        'macro_f1':      f1.mean()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12Q1zUMgDqGl"
   },
   "source": [
    " Use WeightedRandomSampler to balance class sampling in each batch, and customize Trainer to use this sampler during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNwHEoUJXzu"
   },
   "outputs": [],
   "source": [
    "# Extract train labels (0 or 1)\n",
    "train_labels = train_ds[\"labels\"]  # a list or array of 0/1\n",
    "\n",
    "\n",
    "counts = Counter(train_labels)\n",
    "total  = counts[0] + counts[1]\n",
    "# Weight for OBJ = total/counts[0], for SUBJ = total/counts[1]\n",
    "weights = [ total / counts[label] for label in train_labels ]\n",
    "\n",
    "# Sampler that samples N = len(train) items with replacement\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights      = weights,\n",
    "    num_samples  = len(weights),\n",
    "    replacement  = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SamplerTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler      = sampler,\n",
    "            batch_size   = self.args.per_device_train_batch_size,\n",
    "            collate_fn   = self.data_collator,\n",
    "            num_workers  = self.args.dataloader_num_workers,\n",
    "            pin_memory   = True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi7FJKXtHfGa"
   },
   "source": [
    " Initialize model **(mDeBERTaV3_base)** and training configuration with gradient checkpointing and early stopping.\n",
    "\n",
    " Uses a custom SamplerTrainer to address class imbalance, and selects the best model based on macro F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRxFkq-Mfac7",
    "outputId": "863a9907-706c-4dd1-dc33-f1ece53e5bd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-115-1226901342.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SamplerTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SamplerTrainer(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"/content/results_en\",\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy       = 'epoch',\n",
    "    learning_rate       = 3e-5,\n",
    "    per_device_train_batch_size = 32,\n",
    "    gradient_accumulation_steps   = 2,\n",
    "    per_device_eval_batch_size  = 64,\n",
    "    num_train_epochs    = 6,\n",
    "    weight_decay        = 0.01,\n",
    "    warmup_steps        = 6,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    fp16                          = True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'macro_f1',\n",
    "    greater_is_better   = True,\n",
    "    logging_dir         = './logs_en',\n",
    "    logging_steps       = 50,\n",
    "    logging_strategy = 'epoch' ,\n",
    ")\n",
    "\n",
    "trainer = SamplerTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = dev_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6-uUslIHz0b"
   },
   "source": [
    "Train the model and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ss4SWIqlU_Iu",
    "outputId": "978326a9-728c-45d4-9e86-19edb2aafe35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 06:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Obj</th>\n",
       "      <th>Recall Obj</th>\n",
       "      <th>F1 Obj</th>\n",
       "      <th>Precision Subj</th>\n",
       "      <th>Recall Subj</th>\n",
       "      <th>F1 Subj</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.686395</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.341880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.631200</td>\n",
       "      <td>0.622013</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.882883</td>\n",
       "      <td>0.735460</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.639386</td>\n",
       "      <td>0.687423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.535500</td>\n",
       "      <td>0.556950</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.679443</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.766208</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.713253</td>\n",
       "      <td>0.739731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>0.542312</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.747208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.525243</td>\n",
       "      <td>0.768398</td>\n",
       "      <td>0.712177</td>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.782961</td>\n",
       "      <td>0.848168</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.751740</td>\n",
       "      <td>0.767351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.517332</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.785633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_english\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_english\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_model(output_dir)\n",
    "\n",
    "print(f\"Final model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW-cdCvpQ2om"
   },
   "source": [
    "training and evaluation loss logs for each epoch, then evaluate and display final macro F1 scores on the train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "CnmfNKrj39dr",
    "outputId": "b21be369-bbe7-4d96-cd9e-538878dd60b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7024, 'grad_norm': 1.4550509452819824, 'learning_rate': 2.75e-05, 'epoch': 1.0, 'step': 13}\n",
      "{'eval_loss': 0.6863954067230225, 'eval_accuracy': 0.5194805194805194, 'eval_precision_OBJ': 0.0, 'eval_recall_OBJ': 0.0, 'eval_f1_OBJ': 0.0, 'eval_precision_SUBJ': 0.5194805194805194, 'eval_recall_SUBJ': 1.0, 'eval_f1_SUBJ': 0.6837606837606838, 'eval_macro_f1': 0.3418803418803419, 'eval_runtime': 1.1458, 'eval_samples_per_second': 403.202, 'eval_steps_per_second': 6.982, 'epoch': 1.0, 'step': 13}\n",
      "{'loss': 0.6312, 'grad_norm': 2.718979835510254, 'learning_rate': 2.25e-05, 'epoch': 2.0, 'step': 26}\n",
      "{'eval_loss': 0.622012734413147, 'eval_accuracy': 0.6948051948051948, 'eval_precision_OBJ': 0.6302250803858521, 'eval_recall_OBJ': 0.8828828828828829, 'eval_f1_OBJ': 0.7354596622889306, 'eval_precision_SUBJ': 0.8278145695364238, 'eval_recall_SUBJ': 0.5208333333333334, 'eval_f1_SUBJ': 0.639386189258312, 'eval_macro_f1': 0.6874229257736213, 'eval_runtime': 1.1099, 'eval_samples_per_second': 416.262, 'eval_steps_per_second': 7.208, 'epoch': 2.0, 'step': 26}\n",
      "{'loss': 0.5355, 'grad_norm': 4.912708282470703, 'learning_rate': 1.7083333333333333e-05, 'epoch': 3.0, 'step': 39}\n",
      "{'eval_loss': 0.5569499135017395, 'eval_accuracy': 0.7424242424242424, 'eval_precision_OBJ': 0.6794425087108014, 'eval_recall_OBJ': 0.8783783783783784, 'eval_f1_OBJ': 0.7662082514734774, 'eval_precision_SUBJ': 0.8457142857142858, 'eval_recall_SUBJ': 0.6166666666666667, 'eval_f1_SUBJ': 0.7132530120481928, 'eval_macro_f1': 0.7397306317608351, 'eval_runtime': 1.1592, 'eval_samples_per_second': 398.539, 'eval_steps_per_second': 6.901, 'epoch': 3.0, 'step': 39}\n",
      "{'loss': 0.4563, 'grad_norm': 4.733270168304443, 'learning_rate': 1.1666666666666668e-05, 'epoch': 4.0, 'step': 52}\n",
      "{'eval_loss': 0.5423118472099304, 'eval_accuracy': 0.7489177489177489, 'eval_precision_OBJ': 0.6906474820143885, 'eval_recall_OBJ': 0.8648648648648649, 'eval_f1_OBJ': 0.768, 'eval_precision_SUBJ': 0.8369565217391305, 'eval_recall_SUBJ': 0.6416666666666667, 'eval_f1_SUBJ': 0.7264150943396226, 'eval_macro_f1': 0.7472075471698113, 'eval_runtime': 1.1208, 'eval_samples_per_second': 412.192, 'eval_steps_per_second': 7.138, 'epoch': 4.0, 'step': 52}\n",
      "{'loss': 0.3899, 'grad_norm': 2.876716375350952, 'learning_rate': 6.25e-06, 'epoch': 5.0, 'step': 65}\n",
      "{'eval_loss': 0.5252434611320496, 'eval_accuracy': 0.7683982683982684, 'eval_precision_OBJ': 0.7121771217712177, 'eval_recall_OBJ': 0.8693693693693694, 'eval_f1_OBJ': 0.7829614604462475, 'eval_precision_SUBJ': 0.8481675392670157, 'eval_recall_SUBJ': 0.675, 'eval_f1_SUBJ': 0.7517401392111369, 'eval_macro_f1': 0.7673507998286921, 'eval_runtime': 1.1066, 'eval_samples_per_second': 417.506, 'eval_steps_per_second': 7.23, 'epoch': 5.0, 'step': 65}\n",
      "{'loss': 0.3513, 'grad_norm': 4.820737838745117, 'learning_rate': 8.333333333333333e-07, 'epoch': 6.0, 'step': 78}\n",
      "{'eval_loss': 0.5173317790031433, 'eval_accuracy': 0.7857142857142857, 'eval_precision_OBJ': 0.7469879518072289, 'eval_recall_OBJ': 0.8378378378378378, 'eval_f1_OBJ': 0.7898089171974523, 'eval_precision_SUBJ': 0.8309859154929577, 'eval_recall_SUBJ': 0.7375, 'eval_f1_SUBJ': 0.7814569536423841, 'eval_macro_f1': 0.7856329354199182, 'eval_runtime': 1.1134, 'eval_samples_per_second': 414.958, 'eval_steps_per_second': 7.185, 'epoch': 6.0, 'step': 78}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1: 0.9198612172927558\n",
      "Val   macro-F1: 0.7856329354199182\n"
     ]
    }
   ],
   "source": [
    "for record in trainer.state.log_history:\n",
    "    if 'eval_loss' in record or 'loss' in record:\n",
    "        print(record)\n",
    "\n",
    "train_metrics = trainer.evaluate(train_ds)\n",
    "val_metrics   = trainer.evaluate(dev_ds)\n",
    "print(\"Train macro-F1:\", train_metrics['eval_macro_f1'])\n",
    "print(\"Val   macro-F1:\", val_metrics['eval_macro_f1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWiU_W2VQ-s-"
   },
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n50yDmjjHhm5",
    "outputId": "ea21b064-da22-4664-bed1-6f48221f02b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-125-985138441.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/models/Monolingual_english\"\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model            = model,\n",
    "    tokenizer        = tokenizer,\n",
    "    data_collator   = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo0GHwyYRA6a"
   },
   "source": [
    "#Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6a-S9d9RGQu"
   },
   "source": [
    "Result for test data(labeled): **Macro F1: 0.71735**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zvz6tMoXFFDy",
    "outputId": "1e6b8678-79af-428c-c37e-746ac9308a33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of test data\n",
      "OBJ – Precision: 0.84951, Recall: 0.81395, F1: 0.83135\n",
      "SUBJ – Precision: 0.57447, Recall: 0.63529, F1: 0.60335\n",
      "Macro‐F1: 0.71735\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on labeled test set\n",
    "metrics = trainer.evaluate(test_ds)\n",
    "\n",
    "print(\"Result of test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXLhnN6SRWEs"
   },
   "source": [
    "Result for dev test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "aWL_-Eoscm1u",
    "outputId": "9c99f6c3-407b-4275-e0a5-686ed4ec0ecd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of dev_test data\n",
      "OBJ – Precision: 0.82850, Recall: 0.94751, F1: 0.88402\n",
      "SUBJ – Precision: 0.72857, Recall: 0.41803, F1: 0.53125\n",
      "Macro‐F1: 0.70764\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(dev_test_ds)\n",
    "\n",
    "print(\"Result of dev_test data\")\n",
    "print(f\"OBJ – Precision: {metrics['eval_precision_OBJ']:.5f}, Recall: {metrics['eval_recall_OBJ']:.5f}, F1: {metrics['eval_f1_OBJ']:.5f}\")\n",
    "print(f\"SUBJ – Precision: {metrics['eval_precision_SUBJ']:.5f}, Recall: {metrics['eval_recall_SUBJ']:.5f}, F1: {metrics['eval_f1_SUBJ']:.5f}\")\n",
    "print(f\"Macro‐F1: {metrics['eval_macro_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIKoc3N9RguB"
   },
   "source": [
    "Prediction for test unlabeled data and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Obvi8k-4HrZc",
    "outputId": "84fce2bf-76f4-44f8-867d-79bc278d73fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to /content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/english/english_predictions.tsv\n"
     ]
    }
   ],
   "source": [
    "# prediction on the unlabeled test set\n",
    "pred_out = trainer.predict(test_unlabeled_ds)\n",
    "logits   = pred_out.predictions\n",
    "pred_ids = logits.argmax(axis=-1)\n",
    "\n",
    "pred_labels = le.inverse_transform(pred_ids)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sentence': test_unlabeled_df['sentence'],\n",
    "    'prediction': pred_labels\n",
    "})\n",
    "save_path = \"/content/drive/MyDrive/clef2025-checkthat-lab-main-task1/task1/unlabeld_predict/english/english_predictions.tsv\"\n",
    "df.to_csv(save_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved predictions to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
